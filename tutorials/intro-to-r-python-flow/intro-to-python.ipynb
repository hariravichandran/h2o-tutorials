{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Airline Delays in Python\n",
    "\n",
    "The following is a demonstration of predicting potential flight delays using a publicly available airlines dataset. For this example, the dataset used is a small sample of what is more than two decades worth of flight data in order to ensure the download and import process would not take more than a minute or two.\n",
    "\n",
    "## The Data\n",
    "\n",
    "The data comes originally from [RITA](http://www.transtats.bts.gov/OT_Delay/OT_DelayCause1.asp) where it is described in detail. To use the entire 26 years worth of flight information to more accurately predict delays and cancellation please download one of the following and change the path to the data in the notebook: \n",
    "\n",
    "  * [2 Thousand Rows - 4.3MB](https://s3.amazonaws.com/h2o-airlines-unpacked/allyears2k.csv)\n",
    "  * [5.8 Million Rows - 580MB](https://s3.amazonaws.com/h2o-airlines-unpacked/airlines_all.05p.csv)\n",
    "  * [152 Million Rows (Years: 1987-2013) - 14.5GB](https://s3.amazonaws.com/h2o-airlines-unpacked/allyears.1987.2013.csv)\n",
    "\n",
    "## Business Benefits\n",
    "\n",
    "There are obvious benefits to predicting potential delays and logistic issues for a business. It helps the user make contingency plans and corrections to avoid undesirable outcomes. Recommendation engines can forewarn flyers of possible delays and rank flight options accordingly, other businesses might pay more for a flight to ensure certain shipments arrive on time, and airline carriers can use the information to better their flight plans. The goal is to have the machine take in all the possible factors that will affect a flight and return the probability of a flight being delayed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the H2O module and start an local H2O cluster\n",
    "\n",
    "Connection to an H2O cloud is established through the `h2o.init` function from the `h2o` module. To connect to a pre-existing H2O cluster make sure to edit the H2O location with argument `myIP` and `myPort`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-30T12:04:19.476999Z",
     "end_time": "2023-07-30T12:04:19.685318Z"
    }
   },
   "outputs": [],
   "source": [
    "import h2o\n",
    "import os\n",
    "import tabulate\n",
    "import operator \n",
    "from h2o.estimators.glm import H2OGeneralizedLinearEstimator\n",
    "from h2o.estimators.deeplearning import H2ODeepLearningEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-30T12:04:19.489002Z",
     "end_time": "2023-07-30T12:04:19.689314Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/plain": "--------------------------  -----------------------------------\nH2O_cluster_uptime:         1 hour 45 mins\nH2O_cluster_timezone:       America/New_York\nH2O_data_parsing_timezone:  UTC\nH2O_cluster_version:        3.42.0.2\nH2O_cluster_version_age:    5 days\nH2O_cluster_name:           H2O_from_python_Ravichandran_y31k4h\nH2O_cluster_total_nodes:    1\nH2O_cluster_free_memory:    13.53 Gb\nH2O_cluster_total_cores:    16\nH2O_cluster_allowed_cores:  16\nH2O_cluster_status:         locked, healthy\nH2O_connection_url:         http://localhost:54321\nH2O_connection_proxy:       {\"http\": null, \"https\": null}\nH2O_internal_security:      False\nPython_version:             3.9.17 final\n--------------------------  -----------------------------------",
      "text/html": "\n<style>\n\n#h2o-table-22.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-22 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-22 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-22 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-22 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-22 .h2o-table th,\n#h2o-table-22 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-22 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-22\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption></caption>\n    <thead></thead>\n    <tbody><tr><td>H2O_cluster_uptime:</td>\n<td>1 hour 45 mins</td></tr>\n<tr><td>H2O_cluster_timezone:</td>\n<td>America/New_York</td></tr>\n<tr><td>H2O_data_parsing_timezone:</td>\n<td>UTC</td></tr>\n<tr><td>H2O_cluster_version:</td>\n<td>3.42.0.2</td></tr>\n<tr><td>H2O_cluster_version_age:</td>\n<td>5 days</td></tr>\n<tr><td>H2O_cluster_name:</td>\n<td>H2O_from_python_Ravichandran_y31k4h</td></tr>\n<tr><td>H2O_cluster_total_nodes:</td>\n<td>1</td></tr>\n<tr><td>H2O_cluster_free_memory:</td>\n<td>13.53 Gb</td></tr>\n<tr><td>H2O_cluster_total_cores:</td>\n<td>16</td></tr>\n<tr><td>H2O_cluster_allowed_cores:</td>\n<td>16</td></tr>\n<tr><td>H2O_cluster_status:</td>\n<td>locked, healthy</td></tr>\n<tr><td>H2O_connection_url:</td>\n<td>http://localhost:54321</td></tr>\n<tr><td>H2O_connection_proxy:</td>\n<td>{\"http\": null, \"https\": null}</td></tr>\n<tr><td>H2O_internal_security:</td>\n<td>False</td></tr>\n<tr><td>Python_version:</td>\n<td>3.9.17 final</td></tr></tbody>\n  </table>\n</div>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data into H2O\n",
    "\n",
    "We will use the `h2o.importFile` function to do a parallel read of the data into the H2O distributed key-value store. During import of the data, features Year, Month, DayOfWeek, and FlightNum were set to be parsed as enumerator or categorical rather than numeric columns. Once the data is in H2O, get an overview of the airlines dataset quickly by using `describe`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-30T12:04:19.553574Z",
     "end_time": "2023-07-30T12:04:20.068270Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Rows:43978\nCols:31\n",
      "text/html": "<pre style='margin: 1em 0 1em 0;'>Rows:43978\nCols:31\n</pre>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "         Year               Month               DayofMonth          DayOfWeek           DepTime             CRSDepTime          ArrTime             CRSArrTime         UniqueCarrier    FlightNum          TailNum    ActualElapsedTime    CRSElapsedTime     AirTime             ArrDelay            DepDelay            Origin    Dest    Distance           TaxiIn             TaxiOut             Cancelled             CancellationCode    Diverted               CarrierDelay       WeatherDelay        NASDelay           SecurityDelay         LateAircraftDelay    IsArrDelayed    IsDepDelayed\n-------  -----------------  ------------------  ------------------  ------------------  ------------------  ------------------  ------------------  -----------------  ---------------  -----------------  ---------  -------------------  -----------------  ------------------  ------------------  ------------------  --------  ------  -----------------  -----------------  ------------------  --------------------  ------------------  ---------------------  -----------------  ------------------  -----------------  --------------------  -------------------  --------------  --------------\ntype     int                int                 int                 int                 int                 int                 int                 int                enum             int                enum       int                  int                int                 int                 int                 enum      enum    int                int                int                 int                   enum                int                    int                int                 int                int                   int                  enum            enum\nmins     1987.0             1.0                 1.0                 1.0                 1.0                 0.0                 1.0                 0.0                                 1.0                           16.0                 17.0               14.0                -63.0               -16.0                                 11.0               0.0                0.0                 0.0                                       0.0                    0.0                0.0                 0.0                0.0                   0.0\nmean     1997.5             1.4090909090909092  14.601073263904679  3.820614852880986   1345.8466613820756  1313.2228614307153  1504.6341303788884  1485.289167310928                   818.8429896766565             124.81452913540424   125.0215626066189  114.31611109078271  9.317111936984317   10.007390655600112                    730.1821905650503  5.381368059530624  14.168634184732058  0.024694165264450407                      0.0024785119832643593  4.047800291055638  0.2893764692712415  4.855031904175528  0.017015560282100075  7.620060450016793\nmaxs     2008.0             10.0                31.0                7.0                 2400.0              2359.0              2400.0              2359.0                              3949.0                        475.0                437.0              402.0               475.0               473.0                                 3365.0             128.0              254.0               1.0                                       1.0                    369.0              201.0               323.0              14.0                  373.0\nsigma    6.344360901710614  1.8747113713439636  9.17579042586145    1.9050131191328963  465.3408991242338   476.25113999259963  484.347487903516    492.750434122701                    777.4043691636348             73.97444166059017    73.40159463000927  69.63632951506104   29.840221962414844  26.438809042916446                    578.4380082304243  4.201979939864827  9.905085747204327   0.15519314135784237                       0.049723487218862286   16.2057299044842   4.4167798987341245  18.61977622147568  0.40394018210151167   23.487565874106217\nzeros    0                  0                   0                   0                   0                   569                 0                   569                                 0                             0                    0                  0                   1514                6393                                  0                  623                557                 42892                                     43869                  7344               8840                7388               8914                  7140\nmissing  0                  0                   0                   0                   1086                0                   1195                0                  0                0                  32         1195                 13                 16649               1195                1086                0         0       35                 16026              16024               0                     9774                0                      35045              35045               35045              35045                 35045                0               0\n0        1987.0             10.0                14.0                3.0                 741.0               730.0               912.0               849.0              PS               1451.0             NA         91.0                 79.0               nan                 23.0                11.0                SAN       SFO     447.0              nan                nan                 0.0                   NA                  0.0                    nan                nan                 nan                nan                   nan                  YES             YES\n1        1987.0             10.0                15.0                4.0                 729.0               730.0               903.0               849.0              PS               1451.0             NA         94.0                 79.0               nan                 14.0                -1.0                SAN       SFO     447.0              nan                nan                 0.0                   NA                  0.0                    nan                nan                 nan                nan                   nan                  YES             NO\n2        1987.0             10.0                17.0                6.0                 741.0               730.0               918.0               849.0              PS               1451.0             NA         97.0                 79.0               nan                 29.0                11.0                SAN       SFO     447.0              nan                nan                 0.0                   NA                  0.0                    nan                nan                 nan                nan                   nan                  YES             YES\n3        1987.0             10.0                18.0                7.0                 729.0               730.0               847.0               849.0              PS               1451.0             NA         78.0                 79.0               nan                 -2.0                -1.0                SAN       SFO     447.0              nan                nan                 0.0                   NA                  0.0                    nan                nan                 nan                nan                   nan                  NO              NO\n4        1987.0             10.0                19.0                1.0                 749.0               730.0               922.0               849.0              PS               1451.0             NA         93.0                 79.0               nan                 33.0                19.0                SAN       SFO     447.0              nan                nan                 0.0                   NA                  0.0                    nan                nan                 nan                nan                   nan                  YES             YES\n5        1987.0             10.0                21.0                3.0                 728.0               730.0               848.0               849.0              PS               1451.0             NA         80.0                 79.0               nan                 -1.0                -2.0                SAN       SFO     447.0              nan                nan                 0.0                   NA                  0.0                    nan                nan                 nan                nan                   nan                  NO              NO\n6        1987.0             10.0                22.0                4.0                 728.0               730.0               852.0               849.0              PS               1451.0             NA         84.0                 79.0               nan                 3.0                 -2.0                SAN       SFO     447.0              nan                nan                 0.0                   NA                  0.0                    nan                nan                 nan                nan                   nan                  YES             NO\n7        1987.0             10.0                23.0                5.0                 731.0               730.0               902.0               849.0              PS               1451.0             NA         91.0                 79.0               nan                 13.0                1.0                 SAN       SFO     447.0              nan                nan                 0.0                   NA                  0.0                    nan                nan                 nan                nan                   nan                  YES             YES\n8        1987.0             10.0                24.0                6.0                 744.0               730.0               908.0               849.0              PS               1451.0             NA         84.0                 79.0               nan                 19.0                14.0                SAN       SFO     447.0              nan                nan                 0.0                   NA                  0.0                    nan                nan                 nan                nan                   nan                  YES             YES\n9        1987.0             10.0                25.0                7.0                 729.0               730.0               851.0               849.0              PS               1451.0             NA         82.0                 79.0               nan                 2.0                 -1.0                SAN       SFO     447.0              nan                nan                 0.0                   NA                  0.0                    nan                nan                 nan                nan                   nan                  YES             NO\n[43978 rows x 31 columns]\n",
      "text/html": "<table class='dataframe'>\n<thead>\n<tr><th>       </th><th>Year             </th><th>Month             </th><th>DayofMonth        </th><th>DayOfWeek         </th><th>DepTime           </th><th>CRSDepTime        </th><th>ArrTime           </th><th>CRSArrTime       </th><th>UniqueCarrier  </th><th>FlightNum        </th><th>TailNum  </th><th>ActualElapsedTime  </th><th>CRSElapsedTime   </th><th>AirTime           </th><th>ArrDelay          </th><th>DepDelay          </th><th>Origin  </th><th>Dest  </th><th>Distance         </th><th>TaxiIn           </th><th>TaxiOut           </th><th>Cancelled           </th><th>CancellationCode  </th><th>Diverted             </th><th>CarrierDelay     </th><th>WeatherDelay      </th><th>NASDelay         </th><th>SecurityDelay       </th><th>LateAircraftDelay  </th><th>IsArrDelayed  </th><th>IsDepDelayed  </th></tr>\n</thead>\n<tbody>\n<tr><td>type   </td><td>int              </td><td>int               </td><td>int               </td><td>int               </td><td>int               </td><td>int               </td><td>int               </td><td>int              </td><td>enum           </td><td>int              </td><td>enum     </td><td>int                </td><td>int              </td><td>int               </td><td>int               </td><td>int               </td><td>enum    </td><td>enum  </td><td>int              </td><td>int              </td><td>int               </td><td>int                 </td><td>enum              </td><td>int                  </td><td>int              </td><td>int               </td><td>int              </td><td>int                 </td><td>int                </td><td>enum          </td><td>enum          </td></tr>\n<tr><td>mins   </td><td>1987.0           </td><td>1.0               </td><td>1.0               </td><td>1.0               </td><td>1.0               </td><td>0.0               </td><td>1.0               </td><td>0.0              </td><td>               </td><td>1.0              </td><td>         </td><td>16.0               </td><td>17.0             </td><td>14.0              </td><td>-63.0             </td><td>-16.0             </td><td>        </td><td>      </td><td>11.0             </td><td>0.0              </td><td>0.0               </td><td>0.0                 </td><td>                  </td><td>0.0                  </td><td>0.0              </td><td>0.0               </td><td>0.0              </td><td>0.0                 </td><td>0.0                </td><td>              </td><td>              </td></tr>\n<tr><td>mean   </td><td>1997.5           </td><td>1.4090909090909092</td><td>14.601073263904679</td><td>3.820614852880986 </td><td>1345.8466613820756</td><td>1313.2228614307153</td><td>1504.6341303788884</td><td>1485.289167310928</td><td>               </td><td>818.8429896766565</td><td>         </td><td>124.81452913540424 </td><td>125.0215626066189</td><td>114.31611109078271</td><td>9.317111936984317 </td><td>10.007390655600112</td><td>        </td><td>      </td><td>730.1821905650503</td><td>5.381368059530624</td><td>14.168634184732058</td><td>0.024694165264450407</td><td>                  </td><td>0.0024785119832643593</td><td>4.047800291055638</td><td>0.2893764692712415</td><td>4.855031904175528</td><td>0.017015560282100075</td><td>7.620060450016793  </td><td>              </td><td>              </td></tr>\n<tr><td>maxs   </td><td>2008.0           </td><td>10.0              </td><td>31.0              </td><td>7.0               </td><td>2400.0            </td><td>2359.0            </td><td>2400.0            </td><td>2359.0           </td><td>               </td><td>3949.0           </td><td>         </td><td>475.0              </td><td>437.0            </td><td>402.0             </td><td>475.0             </td><td>473.0             </td><td>        </td><td>      </td><td>3365.0           </td><td>128.0            </td><td>254.0             </td><td>1.0                 </td><td>                  </td><td>1.0                  </td><td>369.0            </td><td>201.0             </td><td>323.0            </td><td>14.0                </td><td>373.0              </td><td>              </td><td>              </td></tr>\n<tr><td>sigma  </td><td>6.344360901710614</td><td>1.8747113713439636</td><td>9.17579042586145  </td><td>1.9050131191328963</td><td>465.3408991242338 </td><td>476.25113999259963</td><td>484.347487903516  </td><td>492.750434122701 </td><td>               </td><td>777.4043691636348</td><td>         </td><td>73.97444166059017  </td><td>73.40159463000927</td><td>69.63632951506104 </td><td>29.840221962414844</td><td>26.438809042916446</td><td>        </td><td>      </td><td>578.4380082304243</td><td>4.201979939864827</td><td>9.905085747204327 </td><td>0.15519314135784237 </td><td>                  </td><td>0.049723487218862286 </td><td>16.2057299044842 </td><td>4.4167798987341245</td><td>18.61977622147568</td><td>0.40394018210151167 </td><td>23.487565874106217 </td><td>              </td><td>              </td></tr>\n<tr><td>zeros  </td><td>0                </td><td>0                 </td><td>0                 </td><td>0                 </td><td>0                 </td><td>569               </td><td>0                 </td><td>569              </td><td>               </td><td>0                </td><td>         </td><td>0                  </td><td>0                </td><td>0                 </td><td>1514              </td><td>6393              </td><td>        </td><td>      </td><td>0                </td><td>623              </td><td>557               </td><td>42892               </td><td>                  </td><td>43869                </td><td>7344             </td><td>8840              </td><td>7388             </td><td>8914                </td><td>7140               </td><td>              </td><td>              </td></tr>\n<tr><td>missing</td><td>0                </td><td>0                 </td><td>0                 </td><td>0                 </td><td>1086              </td><td>0                 </td><td>1195              </td><td>0                </td><td>0              </td><td>0                </td><td>32       </td><td>1195               </td><td>13               </td><td>16649             </td><td>1195              </td><td>1086              </td><td>0       </td><td>0     </td><td>35               </td><td>16026            </td><td>16024             </td><td>0                   </td><td>9774              </td><td>0                    </td><td>35045            </td><td>35045             </td><td>35045            </td><td>35045               </td><td>35045              </td><td>0             </td><td>0             </td></tr>\n<tr><td>0      </td><td>1987.0           </td><td>10.0              </td><td>14.0              </td><td>3.0               </td><td>741.0             </td><td>730.0             </td><td>912.0             </td><td>849.0            </td><td>PS             </td><td>1451.0           </td><td>NA       </td><td>91.0               </td><td>79.0             </td><td>nan               </td><td>23.0              </td><td>11.0              </td><td>SAN     </td><td>SFO   </td><td>447.0            </td><td>nan              </td><td>nan               </td><td>0.0                 </td><td>NA                </td><td>0.0                  </td><td>nan              </td><td>nan               </td><td>nan              </td><td>nan                 </td><td>nan                </td><td>YES           </td><td>YES           </td></tr>\n<tr><td>1      </td><td>1987.0           </td><td>10.0              </td><td>15.0              </td><td>4.0               </td><td>729.0             </td><td>730.0             </td><td>903.0             </td><td>849.0            </td><td>PS             </td><td>1451.0           </td><td>NA       </td><td>94.0               </td><td>79.0             </td><td>nan               </td><td>14.0              </td><td>-1.0              </td><td>SAN     </td><td>SFO   </td><td>447.0            </td><td>nan              </td><td>nan               </td><td>0.0                 </td><td>NA                </td><td>0.0                  </td><td>nan              </td><td>nan               </td><td>nan              </td><td>nan                 </td><td>nan                </td><td>YES           </td><td>NO            </td></tr>\n<tr><td>2      </td><td>1987.0           </td><td>10.0              </td><td>17.0              </td><td>6.0               </td><td>741.0             </td><td>730.0             </td><td>918.0             </td><td>849.0            </td><td>PS             </td><td>1451.0           </td><td>NA       </td><td>97.0               </td><td>79.0             </td><td>nan               </td><td>29.0              </td><td>11.0              </td><td>SAN     </td><td>SFO   </td><td>447.0            </td><td>nan              </td><td>nan               </td><td>0.0                 </td><td>NA                </td><td>0.0                  </td><td>nan              </td><td>nan               </td><td>nan              </td><td>nan                 </td><td>nan                </td><td>YES           </td><td>YES           </td></tr>\n<tr><td>3      </td><td>1987.0           </td><td>10.0              </td><td>18.0              </td><td>7.0               </td><td>729.0             </td><td>730.0             </td><td>847.0             </td><td>849.0            </td><td>PS             </td><td>1451.0           </td><td>NA       </td><td>78.0               </td><td>79.0             </td><td>nan               </td><td>-2.0              </td><td>-1.0              </td><td>SAN     </td><td>SFO   </td><td>447.0            </td><td>nan              </td><td>nan               </td><td>0.0                 </td><td>NA                </td><td>0.0                  </td><td>nan              </td><td>nan               </td><td>nan              </td><td>nan                 </td><td>nan                </td><td>NO            </td><td>NO            </td></tr>\n<tr><td>4      </td><td>1987.0           </td><td>10.0              </td><td>19.0              </td><td>1.0               </td><td>749.0             </td><td>730.0             </td><td>922.0             </td><td>849.0            </td><td>PS             </td><td>1451.0           </td><td>NA       </td><td>93.0               </td><td>79.0             </td><td>nan               </td><td>33.0              </td><td>19.0              </td><td>SAN     </td><td>SFO   </td><td>447.0            </td><td>nan              </td><td>nan               </td><td>0.0                 </td><td>NA                </td><td>0.0                  </td><td>nan              </td><td>nan               </td><td>nan              </td><td>nan                 </td><td>nan                </td><td>YES           </td><td>YES           </td></tr>\n<tr><td>5      </td><td>1987.0           </td><td>10.0              </td><td>21.0              </td><td>3.0               </td><td>728.0             </td><td>730.0             </td><td>848.0             </td><td>849.0            </td><td>PS             </td><td>1451.0           </td><td>NA       </td><td>80.0               </td><td>79.0             </td><td>nan               </td><td>-1.0              </td><td>-2.0              </td><td>SAN     </td><td>SFO   </td><td>447.0            </td><td>nan              </td><td>nan               </td><td>0.0                 </td><td>NA                </td><td>0.0                  </td><td>nan              </td><td>nan               </td><td>nan              </td><td>nan                 </td><td>nan                </td><td>NO            </td><td>NO            </td></tr>\n<tr><td>6      </td><td>1987.0           </td><td>10.0              </td><td>22.0              </td><td>4.0               </td><td>728.0             </td><td>730.0             </td><td>852.0             </td><td>849.0            </td><td>PS             </td><td>1451.0           </td><td>NA       </td><td>84.0               </td><td>79.0             </td><td>nan               </td><td>3.0               </td><td>-2.0              </td><td>SAN     </td><td>SFO   </td><td>447.0            </td><td>nan              </td><td>nan               </td><td>0.0                 </td><td>NA                </td><td>0.0                  </td><td>nan              </td><td>nan               </td><td>nan              </td><td>nan                 </td><td>nan                </td><td>YES           </td><td>NO            </td></tr>\n<tr><td>7      </td><td>1987.0           </td><td>10.0              </td><td>23.0              </td><td>5.0               </td><td>731.0             </td><td>730.0             </td><td>902.0             </td><td>849.0            </td><td>PS             </td><td>1451.0           </td><td>NA       </td><td>91.0               </td><td>79.0             </td><td>nan               </td><td>13.0              </td><td>1.0               </td><td>SAN     </td><td>SFO   </td><td>447.0            </td><td>nan              </td><td>nan               </td><td>0.0                 </td><td>NA                </td><td>0.0                  </td><td>nan              </td><td>nan               </td><td>nan              </td><td>nan                 </td><td>nan                </td><td>YES           </td><td>YES           </td></tr>\n<tr><td>8      </td><td>1987.0           </td><td>10.0              </td><td>24.0              </td><td>6.0               </td><td>744.0             </td><td>730.0             </td><td>908.0             </td><td>849.0            </td><td>PS             </td><td>1451.0           </td><td>NA       </td><td>84.0               </td><td>79.0             </td><td>nan               </td><td>19.0              </td><td>14.0              </td><td>SAN     </td><td>SFO   </td><td>447.0            </td><td>nan              </td><td>nan               </td><td>0.0                 </td><td>NA                </td><td>0.0                  </td><td>nan              </td><td>nan               </td><td>nan              </td><td>nan                 </td><td>nan                </td><td>YES           </td><td>YES           </td></tr>\n<tr><td>9      </td><td>1987.0           </td><td>10.0              </td><td>25.0              </td><td>7.0               </td><td>729.0             </td><td>730.0             </td><td>851.0             </td><td>849.0            </td><td>PS             </td><td>1451.0           </td><td>NA       </td><td>82.0               </td><td>79.0             </td><td>nan               </td><td>2.0               </td><td>-1.0              </td><td>SAN     </td><td>SFO   </td><td>447.0            </td><td>nan              </td><td>nan               </td><td>0.0                 </td><td>NA                </td><td>0.0                  </td><td>nan              </td><td>nan               </td><td>nan              </td><td>nan                 </td><td>nan                </td><td>YES           </td><td>NO            </td></tr>\n</tbody>\n</table><pre style='font-size: smaller; margin-bottom: 1em;'>[43978 rows x 31 columns]</pre>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "airlines_hex = h2o.import_file(path = os.path.realpath(\"../data/allyears2k.csv\"),\n",
    "                               destination_frame = \"airlines.hex\")\n",
    "airlines_hex.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a GLM Model\n",
    "\n",
    "Run a logistic regression model using function `h2o.glm` and selecting “binomial” for parameter `Family`. Add some regularization by setting alpha to 0.5 and lambda to 1e-05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-30T12:04:20.071251Z",
     "end_time": "2023-07-30T12:04:20.380936Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Model Details\n=============\nH2OGeneralizedLinearEstimator : Generalized Linear Modeling\nModel Key: glm_model_from_python\n\n\nGLM Model: summary\n    family    link    regularization                                 number_of_predictors_total    number_of_active_predictors    number_of_iterations    training_frame\n--  --------  ------  ---------------------------------------------  ----------------------------  -----------------------------  ----------------------  ----------------\n    binomial  logit   Elastic Net (alpha = 0.5, lambda = 1.507E-4 )  281                           175                            7                       airlines.hex\n\nModelMetricsBinomialGLM: glm\n** Reported on train data. **\n\nMSE: 0.21926317832437667\nRMSE: 0.4682554626743576\nLogLoss: 0.6284201306053259\nAUC: 0.7019232382289031\nAUCPR: 0.715565179443901\nGini: 0.40384647645780625\nNull degrees of freedom: 43977\nResidual degrees of freedom: 43802\nNull deviance: 60855.95153848666\nResidual deviance: 55273.32100752204\nAIC: 55625.32100752204\n\nConfusion Matrix (Act/Pred) for max f1 @ threshold = 0.3833979271338369\n       NO    YES    Error    Rate\n-----  ----  -----  -------  -----------------\nNO     6207  14680  0.7028   (14680.0/20887.0)\nYES    2429  20662  0.1052   (2429.0/23091.0)\nTotal  8636  35342  0.389    (17109.0/43978.0)\n\nMaximum Metrics: Maximum metrics at their respective thresholds\nmetric                       threshold    value     idx\n---------------------------  -----------  --------  -----\nmax f1                       0.383398     0.707203  283\nmax f2                       0.114321     0.846952  393\nmax f0point5                 0.547291     0.666724  183\nmax accuracy                 0.501047     0.649461  211\nmax precision                0.959763     1         0\nmax recall                   0.0862649    1         398\nmax specificity              0.959763     1         0\nmax absolute_mcc             0.547291     0.296624  183\nmax min_per_class_accuracy   0.527903     0.647049  194\nmax mean_per_class_accuracy  0.547291     0.648153  183\nmax tns                      0.959763     20887     0\nmax fns                      0.959763     23076     0\nmax fps                      0.0726623    20887     399\nmax tps                      0.0862649    23091     398\nmax tnr                      0.959763     1         0\nmax fnr                      0.959763     0.99935   0\nmax fpr                      0.0726623    1         399\nmax tpr                      0.0862649    1         398\n\nGains/Lift Table: Avg response rate: 52.51 %, avg score: 52.51 %\ngroup    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score     cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n-------  --------------------------  -----------------  --------  -----------------  ---------------  --------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n1        0.010005                    0.865505           1.83097   1.83097            0.961364         0.910409  0.961364                    0.910409            0.0183188       0.0183188                  83.0967   83.0967            0.0175049\n2        0.0200555                   0.831088           1.62878   1.72964            0.855204         0.845166  0.908163                    0.877713            0.01637         0.0346888                  62.8779   72.9644            0.0308108\n3        0.030015                    0.807682           1.57408   1.67803            0.826484         0.818951  0.881061                    0.858215            0.0156771       0.0503659                  57.4081   67.8025            0.0428493\n4        0.0400655                   0.794741           1.52967   1.64081            0.803167         0.800673  0.861521                    0.84378             0.015374        0.0657399                  52.9674   64.0811            0.054058\n5        0.0500023                   0.779018           1.55589   1.62394            0.816934         0.787002  0.85266                     0.832497            0.0154606       0.0812005                  55.5892   62.3936            0.0656884\n6        0.100005                    0.733366           1.48796   1.55595            0.781264         0.756296  0.816962                    0.794397            0.0744013       0.155602                   48.7958   55.5947            0.117061\n7        0.150007                    0.698152           1.43599   1.51596            0.753979         0.714808  0.795968                    0.767867            0.0718029       0.227405                   43.5992   51.5962            0.162963\n8        0.200009                    0.670561           1.3156    1.46587            0.690769         0.68406   0.769668                    0.746915            0.0657832       0.293188                   31.5604   46.5872            0.19619\n9        0.300014                    0.620483           1.28269   1.40481            0.673488         0.644524  0.737608                    0.712785            0.128275        0.421463                   28.2693   40.4812            0.255714\n10       0.399995                    0.574227           1.1591    1.3434             0.608597         0.597708  0.705361                    0.68402             0.115889        0.537352                   15.9104   34.3396            0.289207\n11       0.500045                    0.530198           1.03062   1.28082            0.541136         0.552555  0.672502                    0.657716            0.103114        0.640466                   3.06221   28.0815            0.295658\n12       0.600005                    0.484931           0.944477  1.22478            0.495905         0.507766  0.643082                    0.632735            0.0944091       0.734875                   -5.55227  22.4782            0.283973\n13       0.699986                    0.437511           0.842906  1.17024            0.442574         0.461548  0.614443                    0.608284            0.0842753       0.81915                    -15.7094  17.0238            0.250902\n14       0.799991                    0.384188           0.725358  1.11462            0.380855         0.411249  0.585242                    0.583653            0.0725391       0.891689                   -27.4642  11.4624            0.193073\n15       0.899995                    0.310559           0.605403  1.05804            0.317872         0.349909  0.555533                    0.55768             0.0605431       0.952232                   -39.4597  5.80414            0.109986\n16       1                           0.0726623          0.477654  1                  0.250796         0.231501  0.525058                    0.525061            0.0477675       1                          -52.2346  0                  0\n\nScoring History: \n    timestamp            duration    iterations    negative_log_likelihood    objective    training_rmse       training_logloss    training_r2          training_auc        training_pr_auc    training_lift       training_classification_error\n--  -------------------  ----------  ------------  -------------------------  -----------  ------------------  ------------------  -------------------  ------------------  -----------------  ------------------  -------------------------------\n    2023-07-30 12:04:20  0.000 sec   0             30428                      0.691891\n    2023-07-30 12:04:20  0.031 sec   1             27733.1                    0.635579\n    2023-07-30 12:04:20  0.040 sec   2             27675.9                    0.634848\n    2023-07-30 12:04:20  0.046 sec   3             27673.2                    0.634836\n    2023-07-30 12:04:20  0.061 sec   4             27638.5                    0.634336\n    2023-07-30 12:04:20  0.071 sec   5             27639.4                    0.634339\n    2023-07-30 12:04:20  0.084 sec   6             27637.2                    0.634321\n    2023-07-30 12:04:20  0.100 sec   7             27636.7                    0.634317     0.4682554626743576  0.6284201306053259  0.12073892565857158  0.7019232382289031  0.715565179443901  1.8309666103676758  0.38903542680431125\n\nVariable Importances: \nvariable          relative_importance    scaled_importance    percentage\n----------------  ---------------------  -------------------  --------------------\nOrigin.MDW        1.7330899238586426     1.0                  0.02824912108345115\nOrigin.AUS        1.3122479915618896     0.7571724776059119   0.02138945700094611\nOrigin.HNL        1.0303770303726196     0.5945317759845571   0.01679500012774701\nUniqueCarrier.WN  0.9742206931114197     0.5621293388760599   0.01587965975847016\nOrigin.ERI        0.9612516760826111     0.55464616281562     0.01566826661185001\nOrigin.ATL        0.8978418111801147     0.5180584104840402   0.014634694766063891\nOrigin.TLH        0.8958194255828857     0.5168914856930137   0.014601730166346902\nOrigin.MYR        0.871356725692749      0.5027764074426759   0.014202991611750721\nOrigin.BUR        0.8667152523994446     0.5000982583002641   0.01412733625234719\nOrigin.LIH        0.8663010001182556     0.49985923303360824  0.014120583998647424\n---               ---                    ---                  ---\nOrigin.SMF        0.0                    0.0                  0.0\nOrigin.STT        0.0                    0.0                  0.0\nOrigin.SWF        0.0                    0.0                  0.0\nOrigin.TRI        0.0                    0.0                  0.0\nOrigin.TUL        0.0                    0.0                  0.0\nOrigin.TYS        0.0                    0.0                  0.0\nOrigin.UCA        0.0                    0.0                  0.0\nUniqueCarrier.AA  0.0                    0.0                  0.0\nUniqueCarrier.CO  0.0                    0.0                  0.0\nUniqueCarrier.PI  0.0                    0.0                  0.0\n[281 rows x 4 columns]\n\n\n[tips]\nUse `model.explain()` to inspect the model.\n--\nUse `h2o.display.toggle_user_tips()` to switch on/off this section.",
      "text/html": "<pre style='margin: 1em 0 1em 0;'>Model Details\n=============\nH2OGeneralizedLinearEstimator : Generalized Linear Modeling\nModel Key: glm_model_from_python\n</pre>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-23.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-23 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-23 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-23 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-23 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-23 .h2o-table th,\n#h2o-table-23 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-23 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-23\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>GLM Model: summary</caption>\n    <thead><tr><th></th>\n<th>family</th>\n<th>link</th>\n<th>regularization</th>\n<th>number_of_predictors_total</th>\n<th>number_of_active_predictors</th>\n<th>number_of_iterations</th>\n<th>training_frame</th></tr></thead>\n    <tbody><tr><td></td>\n<td>binomial</td>\n<td>logit</td>\n<td>Elastic Net (alpha = 0.5, lambda = 1.507E-4 )</td>\n<td>281</td>\n<td>175</td>\n<td>7</td>\n<td>airlines.hex</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomialGLM: glm\n** Reported on train data. **\n\nMSE: 0.21926317832437667\nRMSE: 0.4682554626743576\nLogLoss: 0.6284201306053259\nAUC: 0.7019232382289031\nAUCPR: 0.715565179443901\nGini: 0.40384647645780625\nNull degrees of freedom: 43977\nResidual degrees of freedom: 43802\nNull deviance: 60855.95153848666\nResidual deviance: 55273.32100752204\nAIC: 55625.32100752204</pre>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-24.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-24 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-24 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-24 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-24 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-24 .h2o-table th,\n#h2o-table-24 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-24 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-24\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3833979271338369</caption>\n    <thead><tr><th></th>\n<th>NO</th>\n<th>YES</th>\n<th>Error</th>\n<th>Rate</th></tr></thead>\n    <tbody><tr><td>NO</td>\n<td>6207.0</td>\n<td>14680.0</td>\n<td>0.7028</td>\n<td> (14680.0/20887.0)</td></tr>\n<tr><td>YES</td>\n<td>2429.0</td>\n<td>20662.0</td>\n<td>0.1052</td>\n<td> (2429.0/23091.0)</td></tr>\n<tr><td>Total</td>\n<td>8636.0</td>\n<td>35342.0</td>\n<td>0.389</td>\n<td> (17109.0/43978.0)</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-25.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-25 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-25 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-25 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-25 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-25 .h2o-table th,\n#h2o-table-25 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-25 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-25\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n    <thead><tr><th>metric</th>\n<th>threshold</th>\n<th>value</th>\n<th>idx</th></tr></thead>\n    <tbody><tr><td>max f1</td>\n<td>0.3833979</td>\n<td>0.7072031</td>\n<td>283.0</td></tr>\n<tr><td>max f2</td>\n<td>0.1143210</td>\n<td>0.8469524</td>\n<td>393.0</td></tr>\n<tr><td>max f0point5</td>\n<td>0.5472912</td>\n<td>0.6667238</td>\n<td>183.0</td></tr>\n<tr><td>max accuracy</td>\n<td>0.5010473</td>\n<td>0.6494611</td>\n<td>211.0</td></tr>\n<tr><td>max precision</td>\n<td>0.9597631</td>\n<td>1.0</td>\n<td>0.0</td></tr>\n<tr><td>max recall</td>\n<td>0.0862649</td>\n<td>1.0</td>\n<td>398.0</td></tr>\n<tr><td>max specificity</td>\n<td>0.9597631</td>\n<td>1.0</td>\n<td>0.0</td></tr>\n<tr><td>max absolute_mcc</td>\n<td>0.5472912</td>\n<td>0.2966244</td>\n<td>183.0</td></tr>\n<tr><td>max min_per_class_accuracy</td>\n<td>0.5279034</td>\n<td>0.6470486</td>\n<td>194.0</td></tr>\n<tr><td>max mean_per_class_accuracy</td>\n<td>0.5472912</td>\n<td>0.6481534</td>\n<td>183.0</td></tr>\n<tr><td>max tns</td>\n<td>0.9597631</td>\n<td>20887.0</td>\n<td>0.0</td></tr>\n<tr><td>max fns</td>\n<td>0.9597631</td>\n<td>23076.0</td>\n<td>0.0</td></tr>\n<tr><td>max fps</td>\n<td>0.0726623</td>\n<td>20887.0</td>\n<td>399.0</td></tr>\n<tr><td>max tps</td>\n<td>0.0862649</td>\n<td>23091.0</td>\n<td>398.0</td></tr>\n<tr><td>max tnr</td>\n<td>0.9597631</td>\n<td>1.0</td>\n<td>0.0</td></tr>\n<tr><td>max fnr</td>\n<td>0.9597631</td>\n<td>0.9993504</td>\n<td>0.0</td></tr>\n<tr><td>max fpr</td>\n<td>0.0726623</td>\n<td>1.0</td>\n<td>399.0</td></tr>\n<tr><td>max tpr</td>\n<td>0.0862649</td>\n<td>1.0</td>\n<td>398.0</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-26.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-26 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-26 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-26 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-26 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-26 .h2o-table th,\n#h2o-table-26 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-26 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-26\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Gains/Lift Table: Avg response rate: 52.51 %, avg score: 52.51 %</caption>\n    <thead><tr><th>group</th>\n<th>cumulative_data_fraction</th>\n<th>lower_threshold</th>\n<th>lift</th>\n<th>cumulative_lift</th>\n<th>response_rate</th>\n<th>score</th>\n<th>cumulative_response_rate</th>\n<th>cumulative_score</th>\n<th>capture_rate</th>\n<th>cumulative_capture_rate</th>\n<th>gain</th>\n<th>cumulative_gain</th>\n<th>kolmogorov_smirnov</th></tr></thead>\n    <tbody><tr><td>1</td>\n<td>0.0100050</td>\n<td>0.8655052</td>\n<td>1.8309666</td>\n<td>1.8309666</td>\n<td>0.9613636</td>\n<td>0.9104087</td>\n<td>0.9613636</td>\n<td>0.9104087</td>\n<td>0.0183188</td>\n<td>0.0183188</td>\n<td>83.0966610</td>\n<td>83.0966610</td>\n<td>0.0175049</td></tr>\n<tr><td>2</td>\n<td>0.0200555</td>\n<td>0.8310881</td>\n<td>1.6287794</td>\n<td>1.7296438</td>\n<td>0.8552036</td>\n<td>0.8451658</td>\n<td>0.9081633</td>\n<td>0.8777133</td>\n<td>0.0163700</td>\n<td>0.0346888</td>\n<td>62.8779386</td>\n<td>72.9643761</td>\n<td>0.0308108</td></tr>\n<tr><td>3</td>\n<td>0.0300150</td>\n<td>0.8076817</td>\n<td>1.5740814</td>\n<td>1.6780253</td>\n<td>0.8264840</td>\n<td>0.8189507</td>\n<td>0.8810606</td>\n<td>0.8582148</td>\n<td>0.0156771</td>\n<td>0.0503659</td>\n<td>57.4081424</td>\n<td>67.8025349</td>\n<td>0.0428493</td></tr>\n<tr><td>4</td>\n<td>0.0400655</td>\n<td>0.7947413</td>\n<td>1.5296738</td>\n<td>1.6408112</td>\n<td>0.8031674</td>\n<td>0.8006733</td>\n<td>0.8615210</td>\n<td>0.8437804</td>\n<td>0.0153740</td>\n<td>0.0657399</td>\n<td>52.9673762</td>\n<td>64.0811160</td>\n<td>0.0540580</td></tr>\n<tr><td>5</td>\n<td>0.0500023</td>\n<td>0.7790183</td>\n<td>1.5558922</td>\n<td>1.6239355</td>\n<td>0.8169336</td>\n<td>0.7870019</td>\n<td>0.8526603</td>\n<td>0.8324970</td>\n<td>0.0154606</td>\n<td>0.0812005</td>\n<td>55.5892233</td>\n<td>62.3935502</td>\n<td>0.0656884</td></tr>\n<tr><td>6</td>\n<td>0.1000045</td>\n<td>0.7333656</td>\n<td>1.4879580</td>\n<td>1.5559467</td>\n<td>0.7812642</td>\n<td>0.7562962</td>\n<td>0.8169623</td>\n<td>0.7943966</td>\n<td>0.0744013</td>\n<td>0.1556017</td>\n<td>48.7957969</td>\n<td>55.5946736</td>\n<td>0.1170610</td></tr>\n<tr><td>7</td>\n<td>0.1500068</td>\n<td>0.6981523</td>\n<td>1.4359920</td>\n<td>1.5159618</td>\n<td>0.7539791</td>\n<td>0.7148077</td>\n<td>0.7959679</td>\n<td>0.7678669</td>\n<td>0.0718029</td>\n<td>0.2274046</td>\n<td>43.5992033</td>\n<td>51.5961835</td>\n<td>0.1629626</td></tr>\n<tr><td>8</td>\n<td>0.2000091</td>\n<td>0.6705609</td>\n<td>1.3156043</td>\n<td>1.4658724</td>\n<td>0.6907685</td>\n<td>0.6840601</td>\n<td>0.7696680</td>\n<td>0.7469152</td>\n<td>0.0657832</td>\n<td>0.2931878</td>\n<td>31.5604281</td>\n<td>46.5872447</td>\n<td>0.1961897</td></tr>\n<tr><td>9</td>\n<td>0.3000136</td>\n<td>0.6204829</td>\n<td>1.2826925</td>\n<td>1.4048125</td>\n<td>0.6734879</td>\n<td>0.6445239</td>\n<td>0.7376080</td>\n<td>0.7127848</td>\n<td>0.1282751</td>\n<td>0.4214629</td>\n<td>28.2692522</td>\n<td>40.4812472</td>\n<td>0.2557139</td></tr>\n<tr><td>10</td>\n<td>0.3999955</td>\n<td>0.5742274</td>\n<td>1.1591039</td>\n<td>1.3433958</td>\n<td>0.6085968</td>\n<td>0.5977075</td>\n<td>0.7053607</td>\n<td>0.6840204</td>\n<td>0.1158893</td>\n<td>0.5373522</td>\n<td>15.9103927</td>\n<td>34.3395811</td>\n<td>0.2892074</td></tr>\n<tr><td>11</td>\n<td>0.5000455</td>\n<td>0.5301978</td>\n<td>1.0306221</td>\n<td>1.2808155</td>\n<td>0.5411364</td>\n<td>0.5525548</td>\n<td>0.6725024</td>\n<td>0.6577165</td>\n<td>0.1031138</td>\n<td>0.6404660</td>\n<td>3.0622104</td>\n<td>28.0815469</td>\n<td>0.2956582</td></tr>\n<tr><td>12</td>\n<td>0.6000045</td>\n<td>0.4849307</td>\n<td>0.9444773</td>\n<td>1.2247825</td>\n<td>0.4959054</td>\n<td>0.5077663</td>\n<td>0.6430818</td>\n<td>0.6327352</td>\n<td>0.0944091</td>\n<td>0.7348751</td>\n<td>-5.5522658</td>\n<td>22.4782483</td>\n<td>0.2839726</td></tr>\n<tr><td>13</td>\n<td>0.6999864</td>\n<td>0.4375114</td>\n<td>0.8429059</td>\n<td>1.1702375</td>\n<td>0.4425745</td>\n<td>0.4615484</td>\n<td>0.6144426</td>\n<td>0.6082839</td>\n<td>0.0842753</td>\n<td>0.8191503</td>\n<td>-15.7094080</td>\n<td>17.0237549</td>\n<td>0.2509021</td></tr>\n<tr><td>14</td>\n<td>0.7999909</td>\n<td>0.3841880</td>\n<td>0.7253579</td>\n<td>1.1146244</td>\n<td>0.3808549</td>\n<td>0.4112492</td>\n<td>0.5852425</td>\n<td>0.5836532</td>\n<td>0.0725391</td>\n<td>0.8916894</td>\n<td>-27.4642142</td>\n<td>11.4624426</td>\n<td>0.1930730</td></tr>\n<tr><td>15</td>\n<td>0.8999955</td>\n<td>0.3105593</td>\n<td>0.6054032</td>\n<td>1.0580414</td>\n<td>0.3178718</td>\n<td>0.3499094</td>\n<td>0.5555331</td>\n<td>0.5576803</td>\n<td>0.0605431</td>\n<td>0.9522325</td>\n<td>-39.4596845</td>\n<td>5.8041426</td>\n<td>0.1099861</td></tr>\n<tr><td>16</td>\n<td>1.0</td>\n<td>0.0726623</td>\n<td>0.4776536</td>\n<td>1.0</td>\n<td>0.2507958</td>\n<td>0.2315012</td>\n<td>0.5250580</td>\n<td>0.5250609</td>\n<td>0.0477675</td>\n<td>1.0</td>\n<td>-52.2346438</td>\n<td>0.0</td>\n<td>0.0</td></tr></tbody>\n  </table>\n</div>\n</div></div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-27.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-27 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-27 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-27 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-27 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-27 .h2o-table th,\n#h2o-table-27 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-27 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-27\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Scoring History: </caption>\n    <thead><tr><th></th>\n<th>timestamp</th>\n<th>duration</th>\n<th>iterations</th>\n<th>negative_log_likelihood</th>\n<th>objective</th>\n<th>training_rmse</th>\n<th>training_logloss</th>\n<th>training_r2</th>\n<th>training_auc</th>\n<th>training_pr_auc</th>\n<th>training_lift</th>\n<th>training_classification_error</th></tr></thead>\n    <tbody><tr><td></td>\n<td>2023-07-30 12:04:20</td>\n<td> 0.000 sec</td>\n<td>0</td>\n<td>30427.9757692</td>\n<td>0.6918908</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-07-30 12:04:20</td>\n<td> 0.031 sec</td>\n<td>1</td>\n<td>27733.1096342</td>\n<td>0.6355790</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-07-30 12:04:20</td>\n<td> 0.040 sec</td>\n<td>2</td>\n<td>27675.8625078</td>\n<td>0.6348479</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-07-30 12:04:20</td>\n<td> 0.046 sec</td>\n<td>3</td>\n<td>27673.2467699</td>\n<td>0.6348358</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-07-30 12:04:20</td>\n<td> 0.061 sec</td>\n<td>4</td>\n<td>27638.5288288</td>\n<td>0.6343359</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-07-30 12:04:20</td>\n<td> 0.071 sec</td>\n<td>5</td>\n<td>27639.3502918</td>\n<td>0.6343385</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-07-30 12:04:20</td>\n<td> 0.084 sec</td>\n<td>6</td>\n<td>27637.1643359</td>\n<td>0.6343207</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-07-30 12:04:20</td>\n<td> 0.100 sec</td>\n<td>7</td>\n<td>27636.6605038</td>\n<td>0.6343169</td>\n<td>0.4682555</td>\n<td>0.6284201</td>\n<td>0.1207389</td>\n<td>0.7019232</td>\n<td>0.7155652</td>\n<td>1.8309666</td>\n<td>0.3890354</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-28.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-28 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-28 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-28 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-28 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-28 .h2o-table th,\n#h2o-table-28 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-28 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-28\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Variable Importances: </caption>\n    <thead><tr><th>variable</th>\n<th>relative_importance</th>\n<th>scaled_importance</th>\n<th>percentage</th></tr></thead>\n    <tbody><tr><td>Origin.MDW</td>\n<td>1.7330899</td>\n<td>1.0</td>\n<td>0.0282491</td></tr>\n<tr><td>Origin.AUS</td>\n<td>1.3122480</td>\n<td>0.7571725</td>\n<td>0.0213895</td></tr>\n<tr><td>Origin.HNL</td>\n<td>1.0303770</td>\n<td>0.5945318</td>\n<td>0.0167950</td></tr>\n<tr><td>UniqueCarrier.WN</td>\n<td>0.9742207</td>\n<td>0.5621293</td>\n<td>0.0158797</td></tr>\n<tr><td>Origin.ERI</td>\n<td>0.9612517</td>\n<td>0.5546462</td>\n<td>0.0156683</td></tr>\n<tr><td>Origin.ATL</td>\n<td>0.8978418</td>\n<td>0.5180584</td>\n<td>0.0146347</td></tr>\n<tr><td>Origin.TLH</td>\n<td>0.8958194</td>\n<td>0.5168915</td>\n<td>0.0146017</td></tr>\n<tr><td>Origin.MYR</td>\n<td>0.8713567</td>\n<td>0.5027764</td>\n<td>0.0142030</td></tr>\n<tr><td>Origin.BUR</td>\n<td>0.8667153</td>\n<td>0.5000983</td>\n<td>0.0141273</td></tr>\n<tr><td>Origin.LIH</td>\n<td>0.8663010</td>\n<td>0.4998592</td>\n<td>0.0141206</td></tr>\n<tr><td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td></tr>\n<tr><td>Origin.SMF</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0</td></tr>\n<tr><td>Origin.STT</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0</td></tr>\n<tr><td>Origin.SWF</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0</td></tr>\n<tr><td>Origin.TRI</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0</td></tr>\n<tr><td>Origin.TUL</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0</td></tr>\n<tr><td>Origin.TYS</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0</td></tr>\n<tr><td>Origin.UCA</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0</td></tr>\n<tr><td>UniqueCarrier.AA</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0</td></tr>\n<tr><td>UniqueCarrier.CO</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0</td></tr>\n<tr><td>UniqueCarrier.PI</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0</td></tr></tbody>\n  </table>\n</div>\n<pre style='font-size: smaller; margin-bottom: 1em;'>[281 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n\n[tips]\nUse `model.explain()` to inspect the model.\n--\nUse `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set predictor and response variables\n",
    "myY = \"IsDepDelayed\"\n",
    "myX = [\"Dest\", \"Origin\", \"DayofMonth\", \"Year\", \"UniqueCarrier\", \"DayOfWeek\", \"Month\", \"Distance\"]\n",
    "\n",
    "# GLM - Predict Delays\n",
    "glm_model = H2OGeneralizedLinearEstimator(\n",
    "    family = \"binomial\",standardize = True, solver = \"IRLSM\",\n",
    "    link = \"logit\", alpha = 0.5, model_id = \"glm_model_from_python\" )\n",
    "glm_model.train(x               = myX,\n",
    "               y               = myY,\n",
    "               training_frame  = airlines_hex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-30T12:04:20.365905Z",
     "end_time": "2023-07-30T12:04:20.381912Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC of the training set : 0.7019232382289031\n",
      "Variable Importances:\n",
      "\n",
      "| Predictor        |   Normalized Coefficient |\n",
      "|------------------+--------------------------|\n",
      "| Origin.MDW       |               1.73309    |\n",
      "| Origin.AUS       |               1.31225    |\n",
      "| Origin.HNL       |               1.03038    |\n",
      "| UniqueCarrier.WN |               0.974221   |\n",
      "| Origin.ERI       |               0.961252   |\n",
      "| Origin.ATL       |               0.897842   |\n",
      "| Origin.TLH       |               0.895819   |\n",
      "| Origin.MYR       |               0.871357   |\n",
      "| Origin.BUR       |               0.866715   |\n",
      "| Origin.LIH       |               0.866301   |\n",
      "| Origin.PSP       |               0.845205   |\n",
      "| UniqueCarrier.TW |               0.802473   |\n",
      "| Origin.BNA       |               0.763528   |\n",
      "| Dest.LYH         |               0.755978   |\n",
      "| Origin.HPN       |               0.743651   |\n",
      "| Origin.ABQ       |               0.739158   |\n",
      "| Origin.PBI       |               0.718862   |\n",
      "| Origin.STL       |               0.718767   |\n",
      "| Origin.IAH       |               0.717475   |\n",
      "| Origin.ORD       |               0.672263   |\n",
      "| Origin.MIA       |               0.655131   |\n",
      "| Origin.OGG       |               0.6455     |\n",
      "| Dest.FLL         |               0.632845   |\n",
      "| Origin.BOI       |               0.607348   |\n",
      "| Origin.GSO       |               0.598119   |\n",
      "| UniqueCarrier.HP |               0.59286    |\n",
      "| Origin.BHM       |               0.577035   |\n",
      "| Dest.DAY         |               0.57354    |\n",
      "| Origin.ACY       |               0.572183   |\n",
      "| Dest.TPA         |               0.558315   |\n",
      "| Origin.MCO       |               0.543002   |\n",
      "| Origin.SYR       |               0.533789   |\n",
      "| UniqueCarrier.PS |               0.5279     |\n",
      "| Origin.SRQ       |               0.517633   |\n",
      "| Dest.SFO         |               0.502708   |\n",
      "| Origin.RNO       |               0.50112    |\n",
      "| Dest.CAE         |               0.497314   |\n",
      "| Dest.BTV         |               0.493022   |\n",
      "| Dest.COS         |               0.49009    |\n",
      "| Dest.SLC         |               0.482419   |\n",
      "| Origin.LAX       |               0.479004   |\n",
      "| Origin.PIT       |               0.478452   |\n",
      "| Dest.IAH         |               0.477151   |\n",
      "| Origin.SLC       |               0.476383   |\n",
      "| Dest.SMF         |               0.468452   |\n",
      "| Dest.ICT         |               0.465813   |\n",
      "| Origin.CMH       |               0.463641   |\n",
      "| Origin.LEX       |               0.460759   |\n",
      "| Origin.PWM       |               0.460682   |\n",
      "| Origin.AVP       |               0.457259   |\n",
      "| Origin.OMA       |               0.453693   |\n",
      "| Origin.CRW       |               0.450953   |\n",
      "| Dest.CLE         |               0.45069    |\n",
      "| Origin.LGA       |               0.44322    |\n",
      "| Dest.PBI         |               0.434323   |\n",
      "| Dest.ABQ         |               0.432115   |\n",
      "| Dest.MCO         |               0.420568   |\n",
      "| Dest.IAD         |               0.413774   |\n",
      "| Origin.IAD       |               0.411496   |\n",
      "| Origin.JFK       |               0.411254   |\n",
      "| Origin.SAV       |               0.405571   |\n",
      "| Origin.STX       |               0.403477   |\n",
      "| Origin.CHO       |               0.402679   |\n",
      "| Origin.JAX       |               0.400385   |\n",
      "| Dest.CLT         |               0.396177   |\n",
      "| Origin.IND       |               0.389613   |\n",
      "| Origin.DFW       |               0.388072   |\n",
      "| Dest.IND         |               0.387793   |\n",
      "| Origin.EGE       |               0.387351   |\n",
      "| Dest.CHO         |               0.38449    |\n",
      "| Origin.LYH       |               0.38449    |\n",
      "| Origin.DEN       |               0.367401   |\n",
      "| Year             |               0.367103   |\n",
      "| Origin.ROC       |               0.361497   |\n",
      "| Origin.BDL       |               0.360846   |\n",
      "| Dest.ISP         |               0.360413   |\n",
      "| Dest.OMA         |               0.357252   |\n",
      "| Dest.PNS         |               0.355024   |\n",
      "| Dest.CMH         |               0.347262   |\n",
      "| Origin.BTV       |               0.343696   |\n",
      "| UniqueCarrier.DL |               0.341446   |\n",
      "| Dest.STL         |               0.336437   |\n",
      "| Origin.DAY       |               0.33521    |\n",
      "| Origin.CLE       |               0.33447    |\n",
      "| Origin.SAT       |               0.331597   |\n",
      "| Dest.DFW         |               0.327316   |\n",
      "| Dest.GSO         |               0.322048   |\n",
      "| Dest.SBN         |               0.321649   |\n",
      "| Dest.BUF         |               0.320802   |\n",
      "| UniqueCarrier.UA |               0.320078   |\n",
      "| Dest.MIA         |               0.316073   |\n",
      "| Dest.MDW         |               0.301704   |\n",
      "| Origin.MKE       |               0.29266    |\n",
      "| Dest.MDT         |               0.283629   |\n",
      "| Dest.MKE         |               0.282719   |\n",
      "| DayofMonth       |               0.279329   |\n",
      "| Origin.PHL       |               0.277093   |\n",
      "| Origin.PDX       |               0.270631   |\n",
      "| Dest.FAY         |               0.269575   |\n",
      "| Origin.TUS       |               0.262316   |\n",
      "| Origin.MCI       |               0.259734   |\n",
      "| Dest.BWI         |               0.25404    |\n",
      "| Dest.BUR         |               0.240286   |\n",
      "| Origin.ALB       |               0.237394   |\n",
      "| Origin.BOS       |               0.23722    |\n",
      "| Origin.FLL       |               0.229411   |\n",
      "| Dest.PHL         |               0.229377   |\n",
      "| Dest.HNL         |               0.22879    |\n",
      "| Origin.ONT       |               0.226272   |\n",
      "| Dest.EWR         |               0.22463    |\n",
      "| Origin.TPA       |               0.223234   |\n",
      "| Origin.PVD       |               0.22084    |\n",
      "| Dest.BDL         |               0.22025    |\n",
      "| Origin.MSY       |               0.219824   |\n",
      "| Origin.SFO       |               0.217792   |\n",
      "| Dest.PHF         |               0.217298   |\n",
      "| Origin.SAN       |               0.215957   |\n",
      "| Dest.BGM         |               0.21053    |\n",
      "| Dest.DEN         |               0.209611   |\n",
      "| Dest.SAT         |               0.207606   |\n",
      "| Dest.CHS         |               0.203443   |\n",
      "| Dest.RDU         |               0.194193   |\n",
      "| Dest.ONT         |               0.181662   |\n",
      "| Dest.GEG         |               0.180766   |\n",
      "| Origin.OAK       |               0.168187   |\n",
      "| Dest.MSY         |               0.163774   |\n",
      "| Dest.ATL         |               0.152068   |\n",
      "| Dest.SEA         |               0.148734   |\n",
      "| Dest.HOU         |               0.146954   |\n",
      "| Origin.LAS       |               0.143157   |\n",
      "| Distance         |               0.1316     |\n",
      "| Dest.SNA         |               0.130637   |\n",
      "| Dest.SJC         |               0.130388   |\n",
      "| Dest.ROA         |               0.128022   |\n",
      "| Dest.RSW         |               0.12458    |\n",
      "| Dest.DAL         |               0.124142   |\n",
      "| Origin.OKC       |               0.122144   |\n",
      "| Origin.CLT       |               0.121984   |\n",
      "| Dest.MSP         |               0.121074   |\n",
      "| Origin.MSP       |               0.11412    |\n",
      "| Dest.AVL         |               0.11102    |\n",
      "| Origin.RSW       |               0.110411   |\n",
      "| Dest.LAX         |               0.103705   |\n",
      "| Dest.DTW         |               0.102065   |\n",
      "| Dest.LAS         |               0.101605   |\n",
      "| Dest.ORF         |               0.0997567  |\n",
      "| Dest.SAN         |               0.099634   |\n",
      "| Month            |               0.0990664  |\n",
      "| Origin.DCA       |               0.0878652  |\n",
      "| Origin.RIC       |               0.0857967  |\n",
      "| Origin.ORF       |               0.0845755  |\n",
      "| Dest.LGA         |               0.0842259  |\n",
      "| Origin.CVG       |               0.0697276  |\n",
      "| Origin.MEM       |               0.0694103  |\n",
      "| Dest.BHM         |               0.0654751  |\n",
      "| Dest.PHX         |               0.0653176  |\n",
      "| Origin.GEG       |               0.0627921  |\n",
      "| Origin.EWR       |               0.0566295  |\n",
      "| Dest.OAK         |               0.05637    |\n",
      "| Origin.DTW       |               0.056292   |\n",
      "| Origin.HOU       |               0.0542945  |\n",
      "| Origin.SJC       |               0.0480551  |\n",
      "| Origin.SJU       |               0.0476511  |\n",
      "| UniqueCarrier.US |               0.0454632  |\n",
      "| Dest.TUL         |               0.0445308  |\n",
      "| DayOfWeek        |               0.0413049  |\n",
      "| Dest.ORD         |               0.0405046  |\n",
      "| Origin.DAL       |               0.0399633  |\n",
      "| Dest.BNA         |               0.039296   |\n",
      "| Origin.SNA       |               0.0372608  |\n",
      "| Dest.ROC         |               0.0347609  |\n",
      "| Origin.BWI       |               0.0320618  |\n",
      "| Origin.PHX       |               0.0214955  |\n",
      "| Intercept        |               0.0123217  |\n",
      "| Dest.AUS         |               0.0121815  |\n",
      "| Dest.ABE         |               0.00242002 |\n",
      "| Dest.ACY         |               0          |\n",
      "| Dest.ALB         |               0          |\n",
      "| Dest.AMA         |               0          |\n",
      "| Dest.ANC         |               0          |\n",
      "| Dest.AVP         |               0          |\n",
      "| Dest.BOI         |               0          |\n",
      "| Dest.BOS         |               0          |\n",
      "| Dest.CAK         |               0          |\n",
      "| Dest.CHA         |               0          |\n",
      "| Dest.CRP         |               0          |\n",
      "| Dest.CVG         |               0          |\n",
      "| Dest.DCA         |               0          |\n",
      "| Dest.DSM         |               0          |\n",
      "| Dest.ELM         |               0          |\n",
      "| Dest.ELP         |               0          |\n",
      "| Dest.ERI         |               0          |\n",
      "| Dest.EUG         |               0          |\n",
      "| Dest.EYW         |               0          |\n",
      "| Dest.FAT         |               0          |\n",
      "| Dest.FNT         |               0          |\n",
      "| Dest.GRR         |               0          |\n",
      "| Dest.GSP         |               0          |\n",
      "| Dest.HPN         |               0          |\n",
      "| Dest.HRL         |               0          |\n",
      "| Dest.HTS         |               0          |\n",
      "| Dest.ILM         |               0          |\n",
      "| Dest.JAN         |               0          |\n",
      "| Dest.JAX         |               0          |\n",
      "| Dest.JFK         |               0          |\n",
      "| Dest.KOA         |               0          |\n",
      "| Dest.LBB         |               0          |\n",
      "| Dest.LEX         |               0          |\n",
      "| Dest.LIH         |               0          |\n",
      "| Dest.LIT         |               0          |\n",
      "| Dest.MAF         |               0          |\n",
      "| Dest.MCI         |               0          |\n",
      "| Dest.MHT         |               0          |\n",
      "| Dest.MRY         |               0          |\n",
      "| Dest.MYR         |               0          |\n",
      "| Dest.OAJ         |               0          |\n",
      "| Dest.OGG         |               0          |\n",
      "| Dest.OKC         |               0          |\n",
      "| Dest.ORH         |               0          |\n",
      "| Dest.PDX         |               0          |\n",
      "| Dest.PIT         |               0          |\n",
      "| Dest.PSP         |               0          |\n",
      "| Dest.PVD         |               0          |\n",
      "| Dest.PWM         |               0          |\n",
      "| Dest.RIC         |               0          |\n",
      "| Dest.RNO         |               0          |\n",
      "| Dest.SCK         |               0          |\n",
      "| Dest.SDF         |               0          |\n",
      "| Dest.SJU         |               0          |\n",
      "| Dest.SRQ         |               0          |\n",
      "| Dest.STT         |               0          |\n",
      "| Dest.SWF         |               0          |\n",
      "| Dest.SYR         |               0          |\n",
      "| Dest.TOL         |               0          |\n",
      "| Dest.TUS         |               0          |\n",
      "| Dest.UCA         |               0          |\n",
      "| Origin.ABE       |               0          |\n",
      "| Origin.AMA       |               0          |\n",
      "| Origin.ANC       |               0          |\n",
      "| Origin.BGM       |               0          |\n",
      "| Origin.BIL       |               0          |\n",
      "| Origin.BUF       |               0          |\n",
      "| Origin.CAE       |               0          |\n",
      "| Origin.CHS       |               0          |\n",
      "| Origin.COS       |               0          |\n",
      "| Origin.CRP       |               0          |\n",
      "| Origin.DSM       |               0          |\n",
      "| Origin.ELP       |               0          |\n",
      "| Origin.EYW       |               0          |\n",
      "| Origin.GNV       |               0          |\n",
      "| Origin.GRR       |               0          |\n",
      "| Origin.HRL       |               0          |\n",
      "| Origin.ICT       |               0          |\n",
      "| Origin.ISP       |               0          |\n",
      "| Origin.JAN       |               0          |\n",
      "| Origin.KOA       |               0          |\n",
      "| Origin.LAN       |               0          |\n",
      "| Origin.LBB       |               0          |\n",
      "| Origin.LIT       |               0          |\n",
      "| Origin.MAF       |               0          |\n",
      "| Origin.MDT       |               0          |\n",
      "| Origin.MFR       |               0          |\n",
      "| Origin.MHT       |               0          |\n",
      "| Origin.MLB       |               0          |\n",
      "| Origin.MRY       |               0          |\n",
      "| Origin.PHF       |               0          |\n",
      "| Origin.RDU       |               0          |\n",
      "| Origin.ROA       |               0          |\n",
      "| Origin.SBN       |               0          |\n",
      "| Origin.SCK       |               0          |\n",
      "| Origin.SDF       |               0          |\n",
      "| Origin.SEA       |               0          |\n",
      "| Origin.SMF       |               0          |\n",
      "| Origin.STT       |               0          |\n",
      "| Origin.SWF       |               0          |\n",
      "| Origin.TRI       |               0          |\n",
      "| Origin.TUL       |               0          |\n",
      "| Origin.TYS       |               0          |\n",
      "| Origin.UCA       |               0          |\n",
      "| UniqueCarrier.AA |               0          |\n",
      "| UniqueCarrier.CO |               0          |\n",
      "| UniqueCarrier.PI |               0          |\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC of the training set : \" + str(glm_model.auc()))\n",
    "# Variable importances from each algorithm\n",
    "# Calculate magnitude of normalized GLM coefficients\n",
    "glm_varimp = glm_model.coef_norm()\n",
    "for k,v in glm_varimp.items():\n",
    "    glm_varimp[k] = abs(glm_varimp[k])\n",
    "    \n",
    "# Sort in descending order by magnitude\n",
    "glm_sorted = sorted(glm_varimp.items(), key = operator.itemgetter(1), reverse = True)\n",
    "table = tabulate.tabulate(glm_sorted, headers = [\"Predictor\", \"Normalized Coefficient\"], tablefmt = \"orgtbl\")\n",
    "print(\"Variable Importances:\\n\\n\" + table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Deep Learning Model\n",
    "\n",
    "Build a binary classfication model using function `h2o.deeplearning` and selecting “bernoulli” for parameter `Distribution`. Run 100 passes over the data by setting parameter `epoch` to 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-30T12:04:20.378911Z",
     "end_time": "2023-07-30T12:05:07.834813Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/plain": "Model Details\n=============\nH2ODeepLearningEstimator : Deep Learning\nModel Key: deeplearning_model_from_python\n\n\nStatus of Neuron Layers: predicting IsDepDelayed, 2-class classification, bernoulli distribution, CrossEntropy loss, 97,602 weights/biases, 1.1 MB, 4,400,474 training samples, mini-batch size 1\n    layer    units    type       dropout    l1    l2    mean_rate             rate_rms              momentum    mean_weight            weight_rms           mean_bias            bias_rms\n--  -------  -------  ---------  ---------  ----  ----  --------------------  --------------------  ----------  ---------------------  -------------------  -------------------  -------------------\n    1        284      Input      0.0\n    2        200      Rectifier  0.0        0.0   0.0   0.07507370692978031   0.24492651224136353   0.0         -0.004405406823136837  0.18595975637435913  -0.9848622359400021  0.48988306522369385\n    3        200      Rectifier  0.0        0.0   0.0   0.2748816372255187    0.2558143138885498    0.0         -0.05398843044258877   0.2675340175628662   -0.7228860164345484  1.1734318733215332\n    4        2        Softmax               0.0   0.0   0.012427699869476783  0.011376690119504929  0.0         0.009954080560419243   0.5297868251800537   0.1415117050987444   0.31210005283355713\n\nModelMetricsBinomial: deeplearning\n** Reported on train data. **\n\nMSE: 0.12995973053289067\nRMSE: 0.3604992795178524\nLogLoss: 0.39649470459550645\nMean Per-Class Error: 0.19111141135960696\nAUC: 0.8988111969097996\nAUCPR: 0.9109915685548438\nGini: 0.7976223938195992\n\nConfusion Matrix (Act/Pred) for max f1 @ threshold = 0.4046645554310208\n       NO    YES    Error    Rate\n-----  ----  -----  -------  ---------------\nNO     3560  1141   0.2427   (1141.0/4701.0)\nYES    738   4552   0.1395   (738.0/5290.0)\nTotal  4298  5693   0.1881   (1879.0/9991.0)\n\nMaximum Metrics: Maximum metrics at their respective thresholds\nmetric                       threshold    value     idx\n---------------------------  -----------  --------  -----\nmax f1                       0.404665     0.828917  233\nmax f2                       0.166623     0.894072  323\nmax f0point5                 0.621022     0.84011   156\nmax accuracy                 0.449933     0.813232  217\nmax precision                0.999896     1         0\nmax recall                   0.00416632   1         396\nmax specificity              0.999896     1         0\nmax absolute_mcc             0.449933     0.624872  217\nmax min_per_class_accuracy   0.477292     0.811531  208\nmax mean_per_class_accuracy  0.464839     0.812356  212\nmax tns                      0.999896     4701      0\nmax fns                      0.999896     4935      0\nmax fps                      0.000340982  4701      399\nmax tps                      0.00416632   5290      396\nmax tnr                      0.999896     1         0\nmax fnr                      0.999896     0.932892  0\nmax fpr                      0.000340982  1         399\nmax tpr                      0.00416632   1         396\n\nGains/Lift Table: Avg response rate: 52.95 %, avg score: 50.99 %\ngroup    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n-------  --------------------------  -----------------  ----------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n1        0.010009                    0.999999           1.88866     1.88866            1                1          1                           1                   0.0189036       0.0189036                  88.8658   88.8658            0.0189036\n2        0.020018                    0.999949           1.88866     1.88866            1                0.999986   1                           0.999993            0.0189036       0.0378072                  88.8658   88.8658            0.0378072\n3        0.030027                    0.999767           1.88866     1.88866            1                0.999882   1                           0.999956            0.0189036       0.0567108                  88.8658   88.8658            0.0567108\n4        0.0401361                   0.999171           1.88866     1.88866            1                0.99949    1                           0.999838            0.0190926       0.0758034                  88.8658   88.8658            0.0758034\n5        0.050045                    0.998088           1.88866     1.88866            1                0.998652   1                           0.999604            0.0187146       0.094518                   88.8658   88.8658            0.094518\n6        0.10009                     0.984911           1.88488     1.88677            0.998            0.992787   0.999                       0.996195            0.0943289       0.188847                   88.4881   88.6769            0.188634\n7        0.150035                    0.949654           1.81675     1.86346            0.961924         0.969573   0.986658                    0.987333            0.0907372       0.279584                   81.6745   86.3459            0.27533\n8        0.20008                     0.89536            1.74512     1.83386            0.924            0.922982   0.970985                    0.971237            0.0873346       0.366919                   74.512    83.3859            0.354581\n9        0.30007                     0.781858           1.61453     1.76077            0.854855         0.840421   0.932288                    0.927646            0.161437        0.528355                   61.4528   76.0773            0.485173\n10       0.40006                     0.650917           1.4595      1.68547            0.772773         0.720072   0.892419                    0.875766            0.145936        0.674291                   45.9503   68.5475            0.582821\n11       0.50015                     0.502291           1.19363     1.58705            0.632            0.574153   0.840304                    0.815407            0.119471        0.793762                   19.3632   58.7047            0.624011\n12       0.60004                     0.359999           0.89891     1.47249            0.475952         0.430609   0.77965                     0.751349            0.0897921       0.883554                   -10.109   47.2492            0.60255\n13       0.70013                     0.258623           0.587373    1.34596            0.311            0.319292   0.712652                    0.689582            0.0587902       0.942344                   -41.2627  34.5956            0.514775\n14       0.80002                     0.123965           0.420122    1.23036            0.222445         0.187888   0.651445                    0.626941            0.041966        0.98431                    -57.9878  23.0357            0.39167\n15       0.90001                     0.0312458          0.149353    1.11026            0.0790791        0.0734112  0.587856                    0.565445            0.0149338       0.999244                   -85.0647  11.0259            0.210901\n16       1                           1.39273e-11        0.00756219  1                  0.004004         0.0103592  0.529477                    0.509942            0.000756144     1                          -99.2438  0                  0\n\nScoring History: \n    timestamp            duration    training_speed    epochs    iterations    samples      training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error\n--  -------------------  ----------  ----------------  --------  ------------  -----------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------\n    2023-07-30 12:04:20  0.000 sec                     0         0             0            nan              nan                 nan            nan             nan                nan              nan\n    2023-07-30 12:04:22  2.440 sec   44416 obs/sec     2.26841   1             99760        0.469432         0.629929            0.11546        0.709177        0.732268           1.832            0.373136\n    2023-07-30 12:04:28  8.093 sec   77650 obs/sec     13.645    6             600081       0.445377         0.580311            0.203791       0.76502         0.782973           1.832            0.323391\n    2023-07-30 12:04:33  13.437 sec  84939 obs/sec     25.0116   11            1.09996e+06  0.445438         0.583551            0.203573       0.78244         0.801485           1.86977          0.301672\n    2023-07-30 12:04:38  18.669 sec  88683 obs/sec     36.3784   16            1.59985e+06  0.423761         0.532411            0.279202       0.808552        0.828052           1.88866          0.290662\n    2023-07-30 12:04:44  23.785 sec  91248 obs/sec     47.7531   21            2.10009e+06  0.412482         0.506973            0.317061       0.825699        0.846148           1.88866          0.268842\n    2023-07-30 12:04:49  28.984 sec  92533 obs/sec     59.1187   26            2.59992e+06  0.397318         0.475321            0.366353       0.850352        0.867221           1.88866          0.245821\n    2023-07-30 12:04:54  34.047 sec  93827 obs/sec     70.4996   31            3.10043e+06  0.384848         0.447293            0.405503       0.868724        0.885497           1.88866          0.230708\n    2023-07-30 12:04:59  39.084 sec  94847 obs/sec     81.8684   36            3.60041e+06  0.375841         0.427374            0.433003       0.88095         0.896784           1.88866          0.217095\n    2023-07-30 12:05:05  45.054 sec  95916 obs/sec     95.5131   42            4.20048e+06  0.362471         0.39977             0.472625       0.895755        0.909677           1.88866          0.194775\n    2023-07-30 12:05:07  47.152 sec  96164 obs/sec     100.061   44            4.40047e+06  0.360499         0.396495            0.478348       0.898811        0.910992           1.88866          0.188069\n\nVariable Importances: \nvariable                   relative_importance    scaled_importance    percentage\n-------------------------  ---------------------  -------------------  ---------------------\nDayofMonth                 1.0                    1.0                  0.009892319209539731\nUniqueCarrier.PS           0.9896858334541321     0.9896858334541321   0.00979028818168765\nYear                       0.9787592887878418     0.9787592887878418   0.009682199313991413\nDayOfWeek                  0.9082620739936829     0.9082620739936829   0.008984818361864105\nUniqueCarrier.US           0.7447157502174377     0.7447157502174377   0.007366965921522752\nOrigin.SFO                 0.6747526526451111     0.6747526526451111   0.006674868627449122\nDest.PHX                   0.6635276675224304     0.6635276675224304   0.00656382749149323\nDest.PHL                   0.6591558456420898     0.6591558456420898   0.006520580033925651\nUniqueCarrier.UA           0.6531988382339478     0.6531988382339478   0.006461651415110717\nUniqueCarrier.PI           0.6325972676277161     0.6325972676277161   0.006257854102456002\n---                        ---                    ---                  ---\nOrigin.HRL                 0.1909916251897812     0.1909916251897812   0.0018893501227260849\nOrigin.EYW                 0.18947000801563263    0.18947000801563263  0.0018742977999246895\nDest.CHA                   0.18805119395256042    0.18805119395256042  0.0018602624383137953\nDest.EYW                   0.18677566945552826    0.18677566945552826  0.0018476445428295654\nDest.JAN                   0.18419025838375092    0.18419025838375092  0.0018220688312196658\nDest.LBB                   0.18190164864063263    0.18190164864063263  0.001799429173094677\nDest.AMA                   0.17874746024608612    0.17874746024608612  0.0017682269346487973\nDest.missing(NA)           0.0                    0.0                  0.0\nOrigin.missing(NA)         0.0                    0.0                  0.0\nUniqueCarrier.missing(NA)  0.0                    0.0                  0.0\n[284 rows x 4 columns]\n\n\n[tips]\nUse `model.explain()` to inspect the model.\n--\nUse `h2o.display.toggle_user_tips()` to switch on/off this section.",
      "text/html": "<pre style='margin: 1em 0 1em 0;'>Model Details\n=============\nH2ODeepLearningEstimator : Deep Learning\nModel Key: deeplearning_model_from_python\n</pre>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-29.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-29 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-29 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-29 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-29 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-29 .h2o-table th,\n#h2o-table-29 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-29 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-29\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Status of Neuron Layers: predicting IsDepDelayed, 2-class classification, bernoulli distribution, CrossEntropy loss, 97,602 weights/biases, 1.1 MB, 4,400,474 training samples, mini-batch size 1</caption>\n    <thead><tr><th></th>\n<th>layer</th>\n<th>units</th>\n<th>type</th>\n<th>dropout</th>\n<th>l1</th>\n<th>l2</th>\n<th>mean_rate</th>\n<th>rate_rms</th>\n<th>momentum</th>\n<th>mean_weight</th>\n<th>weight_rms</th>\n<th>mean_bias</th>\n<th>bias_rms</th></tr></thead>\n    <tbody><tr><td></td>\n<td>1</td>\n<td>284</td>\n<td>Input</td>\n<td>0.0</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2</td>\n<td>200</td>\n<td>Rectifier</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0750737</td>\n<td>0.2449265</td>\n<td>0.0</td>\n<td>-0.0044054</td>\n<td>0.1859598</td>\n<td>-0.9848622</td>\n<td>0.4898831</td></tr>\n<tr><td></td>\n<td>3</td>\n<td>200</td>\n<td>Rectifier</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.2748816</td>\n<td>0.2558143</td>\n<td>0.0</td>\n<td>-0.0539884</td>\n<td>0.2675340</td>\n<td>-0.7228860</td>\n<td>1.1734319</td></tr>\n<tr><td></td>\n<td>4</td>\n<td>2</td>\n<td>Softmax</td>\n<td></td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0124277</td>\n<td>0.0113767</td>\n<td>0.0</td>\n<td>0.0099541</td>\n<td>0.5297868</td>\n<td>0.1415117</td>\n<td>0.3121001</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n** Reported on train data. **\n\nMSE: 0.12995973053289067\nRMSE: 0.3604992795178524\nLogLoss: 0.39649470459550645\nMean Per-Class Error: 0.19111141135960696\nAUC: 0.8988111969097996\nAUCPR: 0.9109915685548438\nGini: 0.7976223938195992</pre>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-30.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-30 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-30 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-30 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-30 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-30 .h2o-table th,\n#h2o-table-30 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-30 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-30\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4046645554310208</caption>\n    <thead><tr><th></th>\n<th>NO</th>\n<th>YES</th>\n<th>Error</th>\n<th>Rate</th></tr></thead>\n    <tbody><tr><td>NO</td>\n<td>3560.0</td>\n<td>1141.0</td>\n<td>0.2427</td>\n<td> (1141.0/4701.0)</td></tr>\n<tr><td>YES</td>\n<td>738.0</td>\n<td>4552.0</td>\n<td>0.1395</td>\n<td> (738.0/5290.0)</td></tr>\n<tr><td>Total</td>\n<td>4298.0</td>\n<td>5693.0</td>\n<td>0.1881</td>\n<td> (1879.0/9991.0)</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-31.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-31 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-31 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-31 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-31 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-31 .h2o-table th,\n#h2o-table-31 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-31 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-31\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n    <thead><tr><th>metric</th>\n<th>threshold</th>\n<th>value</th>\n<th>idx</th></tr></thead>\n    <tbody><tr><td>max f1</td>\n<td>0.4046646</td>\n<td>0.8289174</td>\n<td>233.0</td></tr>\n<tr><td>max f2</td>\n<td>0.1666235</td>\n<td>0.8940719</td>\n<td>323.0</td></tr>\n<tr><td>max f0point5</td>\n<td>0.6210219</td>\n<td>0.8401102</td>\n<td>156.0</td></tr>\n<tr><td>max accuracy</td>\n<td>0.4499335</td>\n<td>0.8132319</td>\n<td>217.0</td></tr>\n<tr><td>max precision</td>\n<td>0.9998963</td>\n<td>1.0</td>\n<td>0.0</td></tr>\n<tr><td>max recall</td>\n<td>0.0041663</td>\n<td>1.0</td>\n<td>396.0</td></tr>\n<tr><td>max specificity</td>\n<td>0.9998963</td>\n<td>1.0</td>\n<td>0.0</td></tr>\n<tr><td>max absolute_mcc</td>\n<td>0.4499335</td>\n<td>0.6248724</td>\n<td>217.0</td></tr>\n<tr><td>max min_per_class_accuracy</td>\n<td>0.4772917</td>\n<td>0.8115312</td>\n<td>208.0</td></tr>\n<tr><td>max mean_per_class_accuracy</td>\n<td>0.4648391</td>\n<td>0.8123562</td>\n<td>212.0</td></tr>\n<tr><td>max tns</td>\n<td>0.9998963</td>\n<td>4701.0</td>\n<td>0.0</td></tr>\n<tr><td>max fns</td>\n<td>0.9998963</td>\n<td>4935.0</td>\n<td>0.0</td></tr>\n<tr><td>max fps</td>\n<td>0.0003410</td>\n<td>4701.0</td>\n<td>399.0</td></tr>\n<tr><td>max tps</td>\n<td>0.0041663</td>\n<td>5290.0</td>\n<td>396.0</td></tr>\n<tr><td>max tnr</td>\n<td>0.9998963</td>\n<td>1.0</td>\n<td>0.0</td></tr>\n<tr><td>max fnr</td>\n<td>0.9998963</td>\n<td>0.9328922</td>\n<td>0.0</td></tr>\n<tr><td>max fpr</td>\n<td>0.0003410</td>\n<td>1.0</td>\n<td>399.0</td></tr>\n<tr><td>max tpr</td>\n<td>0.0041663</td>\n<td>1.0</td>\n<td>396.0</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-32.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-32 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-32 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-32 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-32 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-32 .h2o-table th,\n#h2o-table-32 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-32 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-32\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Gains/Lift Table: Avg response rate: 52.95 %, avg score: 50.99 %</caption>\n    <thead><tr><th>group</th>\n<th>cumulative_data_fraction</th>\n<th>lower_threshold</th>\n<th>lift</th>\n<th>cumulative_lift</th>\n<th>response_rate</th>\n<th>score</th>\n<th>cumulative_response_rate</th>\n<th>cumulative_score</th>\n<th>capture_rate</th>\n<th>cumulative_capture_rate</th>\n<th>gain</th>\n<th>cumulative_gain</th>\n<th>kolmogorov_smirnov</th></tr></thead>\n    <tbody><tr><td>1</td>\n<td>0.0100090</td>\n<td>0.9999993</td>\n<td>1.8886578</td>\n<td>1.8886578</td>\n<td>1.0</td>\n<td>0.9999999</td>\n<td>1.0</td>\n<td>0.9999999</td>\n<td>0.0189036</td>\n<td>0.0189036</td>\n<td>88.8657845</td>\n<td>88.8657845</td>\n<td>0.0189036</td></tr>\n<tr><td>2</td>\n<td>0.0200180</td>\n<td>0.9999489</td>\n<td>1.8886578</td>\n<td>1.8886578</td>\n<td>1.0</td>\n<td>0.9999855</td>\n<td>1.0</td>\n<td>0.9999927</td>\n<td>0.0189036</td>\n<td>0.0378072</td>\n<td>88.8657845</td>\n<td>88.8657845</td>\n<td>0.0378072</td></tr>\n<tr><td>3</td>\n<td>0.0300270</td>\n<td>0.9997672</td>\n<td>1.8886578</td>\n<td>1.8886578</td>\n<td>1.0</td>\n<td>0.9998817</td>\n<td>1.0</td>\n<td>0.9999557</td>\n<td>0.0189036</td>\n<td>0.0567108</td>\n<td>88.8657845</td>\n<td>88.8657845</td>\n<td>0.0567108</td></tr>\n<tr><td>4</td>\n<td>0.0401361</td>\n<td>0.9991708</td>\n<td>1.8886578</td>\n<td>1.8886578</td>\n<td>1.0</td>\n<td>0.9994901</td>\n<td>1.0</td>\n<td>0.9998385</td>\n<td>0.0190926</td>\n<td>0.0758034</td>\n<td>88.8657845</td>\n<td>88.8657845</td>\n<td>0.0758034</td></tr>\n<tr><td>5</td>\n<td>0.0500450</td>\n<td>0.9980880</td>\n<td>1.8886578</td>\n<td>1.8886578</td>\n<td>1.0</td>\n<td>0.9986520</td>\n<td>1.0</td>\n<td>0.9996035</td>\n<td>0.0187146</td>\n<td>0.0945180</td>\n<td>88.8657845</td>\n<td>88.8657845</td>\n<td>0.0945180</td></tr>\n<tr><td>6</td>\n<td>0.1000901</td>\n<td>0.9849112</td>\n<td>1.8848805</td>\n<td>1.8867692</td>\n<td>0.998</td>\n<td>0.9927870</td>\n<td>0.999</td>\n<td>0.9961953</td>\n<td>0.0943289</td>\n<td>0.1888469</td>\n<td>88.4880529</td>\n<td>88.6769187</td>\n<td>0.1886342</td></tr>\n<tr><td>7</td>\n<td>0.1500350</td>\n<td>0.9496541</td>\n<td>1.8167450</td>\n<td>1.8634589</td>\n<td>0.9619238</td>\n<td>0.9695726</td>\n<td>0.9866578</td>\n<td>0.9873329</td>\n<td>0.0907372</td>\n<td>0.2795841</td>\n<td>81.6745021</td>\n<td>86.3458941</td>\n<td>0.2753297</td></tr>\n<tr><td>8</td>\n<td>0.2000801</td>\n<td>0.8953598</td>\n<td>1.7451198</td>\n<td>1.8338594</td>\n<td>0.924</td>\n<td>0.9229824</td>\n<td>0.9709855</td>\n<td>0.9712372</td>\n<td>0.0873346</td>\n<td>0.3669187</td>\n<td>74.5119849</td>\n<td>83.3859368</td>\n<td>0.3545809</td></tr>\n<tr><td>9</td>\n<td>0.3000701</td>\n<td>0.7818583</td>\n<td>1.6145283</td>\n<td>1.7607734</td>\n<td>0.8548549</td>\n<td>0.8404205</td>\n<td>0.9322882</td>\n<td>0.9276462</td>\n<td>0.1614367</td>\n<td>0.5283554</td>\n<td>61.4528328</td>\n<td>76.0773408</td>\n<td>0.4851731</td></tr>\n<tr><td>10</td>\n<td>0.4000601</td>\n<td>0.6509172</td>\n<td>1.4595034</td>\n<td>1.6854747</td>\n<td>0.7727728</td>\n<td>0.7200721</td>\n<td>0.8924193</td>\n<td>0.8757657</td>\n<td>0.1459357</td>\n<td>0.6742911</td>\n<td>45.9503360</td>\n<td>68.5474739</td>\n<td>0.5828212</td></tr>\n<tr><td>11</td>\n<td>0.5001501</td>\n<td>0.5022905</td>\n<td>1.1936318</td>\n<td>1.5870471</td>\n<td>0.632</td>\n<td>0.5741528</td>\n<td>0.8403042</td>\n<td>0.8154069</td>\n<td>0.1194707</td>\n<td>0.7937618</td>\n<td>19.3631758</td>\n<td>58.7047086</td>\n<td>0.6240107</td></tr>\n<tr><td>12</td>\n<td>0.6000400</td>\n<td>0.3599988</td>\n<td>0.8989103</td>\n<td>1.4724915</td>\n<td>0.4759519</td>\n<td>0.4306087</td>\n<td>0.7796497</td>\n<td>0.7513487</td>\n<td>0.0897921</td>\n<td>0.8835539</td>\n<td>-10.1089703</td>\n<td>47.2491538</td>\n<td>0.6025498</td></tr>\n<tr><td>13</td>\n<td>0.7001301</td>\n<td>0.2586229</td>\n<td>0.5873726</td>\n<td>1.3459556</td>\n<td>0.311</td>\n<td>0.3192922</td>\n<td>0.7126519</td>\n<td>0.6895823</td>\n<td>0.0587902</td>\n<td>0.9423440</td>\n<td>-41.2627410</td>\n<td>34.5955591</td>\n<td>0.5147754</td></tr>\n<tr><td>14</td>\n<td>0.8000200</td>\n<td>0.1239653</td>\n<td>0.4201223</td>\n<td>1.2303567</td>\n<td>0.2224449</td>\n<td>0.1878883</td>\n<td>0.6514450</td>\n<td>0.6269411</td>\n<td>0.0419660</td>\n<td>0.9843100</td>\n<td>-57.9877714</td>\n<td>23.0356737</td>\n<td>0.3916702</td></tr>\n<tr><td>15</td>\n<td>0.9000100</td>\n<td>0.0312458</td>\n<td>0.1493533</td>\n<td>1.1102586</td>\n<td>0.0790791</td>\n<td>0.0734112</td>\n<td>0.5878559</td>\n<td>0.5654446</td>\n<td>0.0149338</td>\n<td>0.9992439</td>\n<td>-85.0646677</td>\n<td>11.0258604</td>\n<td>0.2109010</td></tr>\n<tr><td>16</td>\n<td>1.0</td>\n<td>0.0000000</td>\n<td>0.0075622</td>\n<td>1.0</td>\n<td>0.0040040</td>\n<td>0.0103592</td>\n<td>0.5294765</td>\n<td>0.5099417</td>\n<td>0.0007561</td>\n<td>1.0</td>\n<td>-99.2437806</td>\n<td>0.0</td>\n<td>0.0</td></tr></tbody>\n  </table>\n</div>\n</div></div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-33.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-33 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-33 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-33 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-33 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-33 .h2o-table th,\n#h2o-table-33 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-33 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-33\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Scoring History: </caption>\n    <thead><tr><th></th>\n<th>timestamp</th>\n<th>duration</th>\n<th>training_speed</th>\n<th>epochs</th>\n<th>iterations</th>\n<th>samples</th>\n<th>training_rmse</th>\n<th>training_logloss</th>\n<th>training_r2</th>\n<th>training_auc</th>\n<th>training_pr_auc</th>\n<th>training_lift</th>\n<th>training_classification_error</th></tr></thead>\n    <tbody><tr><td></td>\n<td>2023-07-30 12:04:20</td>\n<td> 0.000 sec</td>\n<td>None</td>\n<td>0.0</td>\n<td>0</td>\n<td>0.0</td>\n<td>nan</td>\n<td>nan</td>\n<td>nan</td>\n<td>nan</td>\n<td>nan</td>\n<td>nan</td>\n<td>nan</td></tr>\n<tr><td></td>\n<td>2023-07-30 12:04:22</td>\n<td> 2.440 sec</td>\n<td>44416 obs/sec</td>\n<td>2.2684069</td>\n<td>1</td>\n<td>99760.0</td>\n<td>0.4694320</td>\n<td>0.6299290</td>\n<td>0.1154604</td>\n<td>0.7091771</td>\n<td>0.7322682</td>\n<td>1.8319981</td>\n<td>0.3731358</td></tr>\n<tr><td></td>\n<td>2023-07-30 12:04:28</td>\n<td> 8.093 sec</td>\n<td>77650 obs/sec</td>\n<td>13.6450271</td>\n<td>6</td>\n<td>600081.0</td>\n<td>0.4453766</td>\n<td>0.5803110</td>\n<td>0.2037914</td>\n<td>0.7650196</td>\n<td>0.7829732</td>\n<td>1.8319981</td>\n<td>0.3233911</td></tr>\n<tr><td></td>\n<td>2023-07-30 12:04:33</td>\n<td>13.437 sec</td>\n<td>84939 obs/sec</td>\n<td>25.0116422</td>\n<td>11</td>\n<td>1099962.0</td>\n<td>0.4454378</td>\n<td>0.5835513</td>\n<td>0.2035726</td>\n<td>0.7824397</td>\n<td>0.8014845</td>\n<td>1.8697713</td>\n<td>0.3016715</td></tr>\n<tr><td></td>\n<td>2023-07-30 12:04:38</td>\n<td>18.669 sec</td>\n<td>88683 obs/sec</td>\n<td>36.3784392</td>\n<td>16</td>\n<td>1599851.0</td>\n<td>0.4237609</td>\n<td>0.5324108</td>\n<td>0.2792016</td>\n<td>0.8085517</td>\n<td>0.8280524</td>\n<td>1.8886578</td>\n<td>0.2906616</td></tr>\n<tr><td></td>\n<td>2023-07-30 12:04:44</td>\n<td>23.785 sec</td>\n<td>91248 obs/sec</td>\n<td>47.7531266</td>\n<td>21</td>\n<td>2100087.0</td>\n<td>0.4124820</td>\n<td>0.5069729</td>\n<td>0.3170609</td>\n<td>0.8256994</td>\n<td>0.8461476</td>\n<td>1.8886578</td>\n<td>0.2688420</td></tr>\n<tr><td></td>\n<td>2023-07-30 12:04:49</td>\n<td>28.984 sec</td>\n<td>92533 obs/sec</td>\n<td>59.1186957</td>\n<td>26</td>\n<td>2599922.0</td>\n<td>0.3973176</td>\n<td>0.4753209</td>\n<td>0.3663527</td>\n<td>0.8503522</td>\n<td>0.8672209</td>\n<td>1.8886578</td>\n<td>0.2458212</td></tr>\n<tr><td></td>\n<td>2023-07-30 12:04:54</td>\n<td>34.047 sec</td>\n<td>93827 obs/sec</td>\n<td>70.4995907</td>\n<td>31</td>\n<td>3100431.0</td>\n<td>0.3848477</td>\n<td>0.4472930</td>\n<td>0.4055027</td>\n<td>0.8687243</td>\n<td>0.8854971</td>\n<td>1.8886578</td>\n<td>0.2307076</td></tr>\n<tr><td></td>\n<td>2023-07-30 12:04:59</td>\n<td>39.084 sec</td>\n<td>94847 obs/sec</td>\n<td>81.8683660</td>\n<td>36</td>\n<td>3600407.0</td>\n<td>0.3758412</td>\n<td>0.4273738</td>\n<td>0.4330031</td>\n<td>0.8809501</td>\n<td>0.8967838</td>\n<td>1.8886578</td>\n<td>0.2170954</td></tr>\n<tr><td></td>\n<td>2023-07-30 12:05:05</td>\n<td>45.054 sec</td>\n<td>95916 obs/sec</td>\n<td>95.5131429</td>\n<td>42</td>\n<td>4200477.0</td>\n<td>0.3624713</td>\n<td>0.3997701</td>\n<td>0.4726253</td>\n<td>0.8957555</td>\n<td>0.9096769</td>\n<td>1.8886578</td>\n<td>0.1947753</td></tr>\n<tr><td></td>\n<td>2023-07-30 12:05:07</td>\n<td>47.152 sec</td>\n<td>96164 obs/sec</td>\n<td>100.0608031</td>\n<td>44</td>\n<td>4400474.0</td>\n<td>0.3604993</td>\n<td>0.3964947</td>\n<td>0.4783481</td>\n<td>0.8988112</td>\n<td>0.9109916</td>\n<td>1.8886578</td>\n<td>0.1880693</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-34.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-34 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-34 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-34 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-34 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-34 .h2o-table th,\n#h2o-table-34 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-34 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-34\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Variable Importances: </caption>\n    <thead><tr><th>variable</th>\n<th>relative_importance</th>\n<th>scaled_importance</th>\n<th>percentage</th></tr></thead>\n    <tbody><tr><td>DayofMonth</td>\n<td>1.0</td>\n<td>1.0</td>\n<td>0.0098923</td></tr>\n<tr><td>UniqueCarrier.PS</td>\n<td>0.9896858</td>\n<td>0.9896858</td>\n<td>0.0097903</td></tr>\n<tr><td>Year</td>\n<td>0.9787593</td>\n<td>0.9787593</td>\n<td>0.0096822</td></tr>\n<tr><td>DayOfWeek</td>\n<td>0.9082621</td>\n<td>0.9082621</td>\n<td>0.0089848</td></tr>\n<tr><td>UniqueCarrier.US</td>\n<td>0.7447158</td>\n<td>0.7447158</td>\n<td>0.0073670</td></tr>\n<tr><td>Origin.SFO</td>\n<td>0.6747527</td>\n<td>0.6747527</td>\n<td>0.0066749</td></tr>\n<tr><td>Dest.PHX</td>\n<td>0.6635277</td>\n<td>0.6635277</td>\n<td>0.0065638</td></tr>\n<tr><td>Dest.PHL</td>\n<td>0.6591558</td>\n<td>0.6591558</td>\n<td>0.0065206</td></tr>\n<tr><td>UniqueCarrier.UA</td>\n<td>0.6531988</td>\n<td>0.6531988</td>\n<td>0.0064617</td></tr>\n<tr><td>UniqueCarrier.PI</td>\n<td>0.6325973</td>\n<td>0.6325973</td>\n<td>0.0062579</td></tr>\n<tr><td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td></tr>\n<tr><td>Origin.HRL</td>\n<td>0.1909916</td>\n<td>0.1909916</td>\n<td>0.0018894</td></tr>\n<tr><td>Origin.EYW</td>\n<td>0.1894700</td>\n<td>0.1894700</td>\n<td>0.0018743</td></tr>\n<tr><td>Dest.CHA</td>\n<td>0.1880512</td>\n<td>0.1880512</td>\n<td>0.0018603</td></tr>\n<tr><td>Dest.EYW</td>\n<td>0.1867757</td>\n<td>0.1867757</td>\n<td>0.0018476</td></tr>\n<tr><td>Dest.JAN</td>\n<td>0.1841903</td>\n<td>0.1841903</td>\n<td>0.0018221</td></tr>\n<tr><td>Dest.LBB</td>\n<td>0.1819016</td>\n<td>0.1819016</td>\n<td>0.0017994</td></tr>\n<tr><td>Dest.AMA</td>\n<td>0.1787475</td>\n<td>0.1787475</td>\n<td>0.0017682</td></tr>\n<tr><td>Dest.missing(NA)</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0</td></tr>\n<tr><td>Origin.missing(NA)</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0</td></tr>\n<tr><td>UniqueCarrier.missing(NA)</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0</td></tr></tbody>\n  </table>\n</div>\n<pre style='font-size: smaller; margin-bottom: 1em;'>[284 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n\n[tips]\nUse `model.explain()` to inspect the model.\n--\nUse `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deep Learning - Predict Delays\n",
    "deeplearning_model = H2ODeepLearningEstimator(\n",
    "    distribution = \"bernoulli\", model_id = \"deeplearning_model_from_python\",\n",
    "    epochs = 100, hidden = [200,200],  \n",
    "    seed = 6765686131094811000, variable_importances = True)\n",
    "deeplearning_model.train(x               = myX,\n",
    "                         y               = myY,\n",
    "                         training_frame  = airlines_hex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-30T12:05:07.837831Z",
     "end_time": "2023-07-30T12:05:07.884808Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC of the training set : 0.8988111969097996\n"
     ]
    },
    {
     "data": {
      "text/plain": "                      variable  relative_importance  scaled_importance  \\\n0                   DayofMonth             1.000000           1.000000   \n1             UniqueCarrier.PS             0.989686           0.989686   \n2                         Year             0.978759           0.978759   \n3                    DayOfWeek             0.908262           0.908262   \n4             UniqueCarrier.US             0.744716           0.744716   \n..                         ...                  ...                ...   \n279                   Dest.LBB             0.181902           0.181902   \n280                   Dest.AMA             0.178747           0.178747   \n281           Dest.missing(NA)             0.000000           0.000000   \n282         Origin.missing(NA)             0.000000           0.000000   \n283  UniqueCarrier.missing(NA)             0.000000           0.000000   \n\n     percentage  \n0      0.009892  \n1      0.009790  \n2      0.009682  \n3      0.008985  \n4      0.007367  \n..          ...  \n279    0.001799  \n280    0.001768  \n281    0.000000  \n282    0.000000  \n283    0.000000  \n\n[284 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>variable</th>\n      <th>relative_importance</th>\n      <th>scaled_importance</th>\n      <th>percentage</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>DayofMonth</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.009892</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>UniqueCarrier.PS</td>\n      <td>0.989686</td>\n      <td>0.989686</td>\n      <td>0.009790</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Year</td>\n      <td>0.978759</td>\n      <td>0.978759</td>\n      <td>0.009682</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>DayOfWeek</td>\n      <td>0.908262</td>\n      <td>0.908262</td>\n      <td>0.008985</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>UniqueCarrier.US</td>\n      <td>0.744716</td>\n      <td>0.744716</td>\n      <td>0.007367</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>279</th>\n      <td>Dest.LBB</td>\n      <td>0.181902</td>\n      <td>0.181902</td>\n      <td>0.001799</td>\n    </tr>\n    <tr>\n      <th>280</th>\n      <td>Dest.AMA</td>\n      <td>0.178747</td>\n      <td>0.178747</td>\n      <td>0.001768</td>\n    </tr>\n    <tr>\n      <th>281</th>\n      <td>Dest.missing(NA)</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>282</th>\n      <td>Origin.missing(NA)</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>283</th>\n      <td>UniqueCarrier.missing(NA)</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>284 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"AUC of the training set : \" + str(deeplearning_model.auc()))\n",
    "deeplearning_model.varimp(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shut down the cluster\n",
    "\n",
    "Shut down the cluster now that we are done using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-07-30T12:05:07.869809Z",
     "end_time": "2023-07-30T12:05:08.054143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H2O session _sid_a81b closed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ravichandran\\AppData\\Local\\Temp\\ipykernel_34948\\1954269801.py:1: H2ODeprecationWarning: Deprecated, use ``h2o.cluster().shutdown()``.\n",
      "  h2o.shutdown(prompt=False)\n"
     ]
    }
   ],
   "source": [
    "h2o.shutdown(prompt=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
